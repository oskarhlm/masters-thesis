@misc{AgentProtocol,
  title = {Agent {{Protocol}}},
  url = {https://agentprotocol.ai/},
  urldate = {2023-12-11},
  file = {C:\Users\oskar\Zotero\storage\EXGN5DIA\agentprotocol.ai.html}
}

@misc{bastianLargeLanguageModels2023,
  title = {Large Language Models Are Powerful Imitators, but Not Innovators},
  author = {Bastian, Matthias},
  year = {2023},
  month = oct,
  journal = {THE DECODER},
  url = {https://the-decoder.com/large-language-models-are-powerful-imitators-but-not-innovators/},
  urldate = {2023-10-30},
  abstract = {According to a psychological study, large AI models such as OpenAI's ChatGPT are strong imitators that mimic human content but are not innovative.},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\KXKCWKT9\large-language-models-are-powerful-imitators-but-not-innovators.html}
}

@article{blancOGCAPIState,
  title = {{{OGC API}} State of Play: A Practical Testbed for the National Spatial Data Infrastructure in {{Switzerland}}},
  shorttitle = {{{OGC API}} State of Play},
  editor = {Blanc, Nicolas and Cannata, Massimiliano and Collombin, Maxime and Ertz, Olivier and Giuliani, Gregory and Ingensand, Jens},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences ; Proceedings of the Free and Open Source Software for Geospatial (FOSS4G) 2022 {\textendash} Academic Track},
  publisher = {{22-28 August 2022}},
  address = {{Florence, Italy}},
  issn = {2194-9034},
  abstract = {Interoperability standards from the Open Geospatial Consortium (OGC) shape a backbone within the OSGeo community by defining a pathway to software implementation toward the standardization of geospatial information and related services ensuring interoperability between FOSS4G software. In 2016, the OGC has initiated the creation of a new generation of standards based on the OpenAPI specifications to facilitate the integration of geospatial data in modern web applications and systems. From a practical perspective this paper intends to address the question how organizations and institutions anticipate to leverage this new generation of standards in order to deploy a geospatial data infrastructure. This issue is at the core of this article and at the center of a project that seeks to address the issue by running a Testbed Platform with a special focus to the Swiss context. To challenge these standards, the Testbed platform is configured to run a showcase with experimental cases about climate change. It is expected to bring good visibility toward all actors concerned by the Swiss standardization process and to raise interest from government stakeholders, technical or not, companies and universities as a community in synergy when considering the advances at the OGC},
  langid = {english},
  keywords = {climate change,e-government,geospatial standardization process,national SDI,OGC API,published full paper,testbed platform},
  file = {C:\Users\oskar\Zotero\storage\GVU3CC45\Blanc et al. - OGC API state of play a practical testbed for the.pdf}
}

@article{brownEstimateUpperBound1992,
  title = {An {{Estimate}} of an {{Upper Bound}} for the {{Entropy}} of {{English}}},
  author = {Brown, Peter F. and Della Pietra, Stephen A. and Della Pietra, Vincent J. and Lai, Jennifer C. and Mercer, Robert L.},
  year = {1992},
  journal = {Computational Linguistics},
  volume = {18},
  number = {1},
  pages = {31--40},
  url = {https://aclanthology.org/J92-1002},
  urldate = {2023-12-07},
  file = {C:\Users\oskar\Zotero\storage\AUAZZCJG\Brown et al. - 1992 - An Estimate of an Upper Bound for the Entropy of E.pdf}
}

@techreport{cannataOpenGeospatialStandards2023,
  type = {Other},
  title = {Open Geospatial Standards and Reproducible Research},
  author = {Cannata, Massimiliano and Giuliani, Gregory and Ingensand, Jens and Ertz, Olivier and Collombin, Maxime},
  year = {2023},
  month = may,
  institution = {{display}},
  doi = {10.5194/egusphere-egu23-14845},
  url = {https://meetingorganizer.copernicus.org/EGU23/EGU23-14845.html},
  urldate = {2023-10-23},
  abstract = {In the era of cloud computing, big data and Internet of things, research is very often data-driven: based on the analysis of data, increasingly available in large quantities and collected by experiments, observations or simulations. These data are very often characterized as being dynamic in space and time and as continuously expanding (monitoring) or change (data quality management or survey). Modern Spatial Data Infrastructures (e.g.\&\#160; swisstopo or INSPIRE), are based on interoperable Web services which expose and serve large quantities of data on the Internet using widely accepted and used open standards defined by the Open Geospatial Consortium (OGC) and the International Organization for Standardization (ISO). These standards mostly comply with FAIR principles but do not offer any capability to retrieve a dataset how it was in a defined instant, to refer to its status in that specific instant and to guarantee its immutability. These three aspects hinder the replicability of research based on such a kind of services. We discuss the issue here and the state of the art\&\#160; and propose a possible solution to fill this gap, using or extending when needed the existing standards and or adopting best practices in the fields of sensor data, satellite data and vector data.},
  file = {C:\Users\oskar\Zotero\storage\T246WAYX\EGU23-14845_presentation.pdf}
}

@misc{ceylanLargeLanguageModel2023,
  title = {Large {{Language Model Evaluation}} in 2023: 5 {{Methods}}},
  shorttitle = {Large {{Language Model Evaluation}} in 2023},
  author = {Ceylan, Burak},
  year = {2023},
  month = dec,
  url = {https://research.aimultiple.com/large-language-model-evaluation/},
  urldate = {2023-12-16},
  abstract = {Large Language Models (LLMs) have expanded rapidly and may lead the AI transformation. This makes LLM evaluation important more than ever.},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\W6TKFU9N\large-language-model-evaluation.html}
}

@misc{chaseLangChain2022,
  title = {{{LangChain}}},
  author = {Chase, Harrison},
  year = {2022},
  month = oct,
  url = {https://github.com/langchain-ai/langchain},
  urldate = {2023-10-05},
  abstract = {⚡ Building applications with LLMs through composability ⚡},
  copyright = {MIT}
}

@misc{chenEvaluatingLargeLanguage2021,
  title = {Evaluating {{Large Language Models Trained}} on {{Code}}},
  author = {Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and Ray, Alex and Puri, Raul and Krueger, Gretchen and Petrov, Michael and Khlaaf, Heidy and Sastry, Girish and Mishkin, Pamela and Chan, Brooke and Gray, Scott and Ryder, Nick and Pavlov, Mikhail and Power, Alethea and Kaiser, Lukasz and Bavarian, Mohammad and Winter, Clemens and Tillet, Philippe and Such, Felipe Petroski and Cummings, Dave and Plappert, Matthias and Chantzis, Fotios and Barnes, Elizabeth and {Herbert-Voss}, Ariel and Guss, William Hebgen and Nichol, Alex and Paino, Alex and Tezak, Nikolas and Tang, Jie and Babuschkin, Igor and Balaji, Suchir and Jain, Shantanu and Saunders, William and Hesse, Christopher and Carr, Andrew N. and Leike, Jan and Achiam, Josh and Misra, Vedant and Morikawa, Evan and Radford, Alec and Knight, Matthew and Brundage, Miles and Murati, Mira and Mayer, Katie and Welinder, Peter and McGrew, Bob and Amodei, Dario and McCandlish, Sam and Sutskever, Ilya and Zaremba, Wojciech},
  year = {2021},
  month = jul,
  number = {arXiv:2107.03374},
  eprint = {2107.03374},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2107.03374},
  url = {http://arxiv.org/abs/2107.03374},
  urldate = {2023-10-30},
  abstract = {We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8\% of the problems, while GPT-3 solves 0\% and GPT-J solves 11.4\%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2\% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\JGC3GF77\\Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf;C\:\\Users\\oskar\\Zotero\\storage\\LRYWFJMQ\\2107.html}
}

@misc{clearyLatencyBenchmarksComparisons2023,
  title = {Latency {{Benchmarks}} and {{Comparisons}} for {{OpenAI}}, {{Azure}}, and {{Anthropic}}},
  author = {Cleary, Dan},
  year = {2023},
  month = oct,
  journal = {Medium},
  url = {https://medium.com/@dan_43009/latency-benchmarks-and-comparisons-for-openai-azure-and-anthropic-6f035f1acab6},
  urldate = {2023-12-11},
  abstract = {‍We just recently launched Anthropic's models on PromptHub. Their larger context windows allow for way more token usage. I've been chatting{\ldots}},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\57PT76U8\latency-benchmarks-and-comparisons-for-openai-azure-and-anthropic-6f035f1acab6.html}
}

@article{coetzeeOpenGeospatialSoftware2020,
  title = {Open {{Geospatial Software}} and {{Data}}: {{A Review}} of the {{Current State}} and {{A Perspective}} into the {{Future}}},
  shorttitle = {Open {{Geospatial Software}} and {{Data}}},
  author = {Coetzee, Serena and Iv{\'a}nov{\'a}, Ivana and Mitasova, Helena and Brovelli, Maria Antonia},
  year = {2020},
  month = feb,
  journal = {ISPRS International Journal of Geo-Information},
  volume = {9},
  number = {2},
  pages = {90},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2220-9964},
  doi = {10.3390/ijgi9020090},
  url = {https://www.mdpi.com/2220-9964/9/2/90},
  urldate = {2023-10-23},
  abstract = {All over the world, organizations are increasingly considering the adoption of open source software and open data. In the geospatial domain, this is no different, and the last few decades have seen significant advances in this regard. We review the current state of open source geospatial software, focusing on the Open Source Geospatial Foundation (OSGeo) software ecosystem and its communities, as well as three kinds of open geospatial data (collaboratively contributed, authoritative and scientific). The current state confirms that openness has changed the way in which geospatial data are collected, processed, analyzed, and visualized. A perspective on future developments, informed by responses from professionals in key organizations in the global geospatial community, suggests that open source geospatial software and open geospatial data are likely to have an even more profound impact in the future.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {geospatial data,geospatial software,open data,open source software},
  file = {C:\Users\oskar\Zotero\storage\TUXR534A\Coetzee et al. - 2020 - Open Geospatial Software and Data A Review of the.pdf}
}

@misc{datatilsynetGeneralDataProtection,
  title = {General {{Data Protection Regulation}}},
  author = {{Datatilsynet}},
  journal = {Datatilsynet},
  url = {https://www.datatilsynet.no/en/regulations-and-tools/regulations/},
  urldate = {2023-12-05},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\MM6JTID7\regulations.html}
}

@misc{dengK2FoundationLanguage2023,
  title = {K2: {{A Foundation Language Model}} for {{Geoscience Knowledge Understanding}} and {{Utilization}}},
  shorttitle = {K2},
  author = {Deng, Cheng and Zhang, Tianhang and He, Zhongmou and Xu, Yi and Chen, Qiyuan and Shi, Yuanyuan and Fu, Luoyi and Zhang, Weinan and Wang, Xinbing and Zhou, Chenghu and Lin, Zhouhan and He, Junxian},
  year = {2023},
  month = jun,
  journal = {arXiv.org},
  url = {https://arxiv.org/abs/2306.05064v2},
  urldate = {2023-10-09},
  abstract = {Large language models (LLMs) have achieved great success in general domains of natural language processing. In this paper, we bring LLMs to the realm of geoscience with the objective of advancing research and applications in this field. To this end, we present the first-ever LLM in geoscience, K2, alongside a suite of resources developed to further promote LLM research within geoscience. For instance, we have curated the first geoscience instruction tuning dataset, GeoSignal, which aims to align LLM responses to geoscience-related user queries. Additionally, we have established the first geoscience benchmark, GeoBench, to evaluate LLMs in the context of geoscience. In this work, we experiment with a complete recipe to adapt a pre-trained general-domain LLM to the geoscience domain. Specifically, we further train the LLaMA-7B model on 5.5B tokens of geoscience text corpus, including over 1 million pieces of geoscience literature, and utilize GeoSignal's supervised data to fine-tune the model. Moreover, we share a protocol that can efficiently gather domain-specific data and construct domain-supervised data, even in situations where manpower is scarce. Meanwhile, we equip K2 with the abilities of using tools to be a naive geoscience aide. Experiments conducted on the GeoBench demonstrate the effectiveness of our approach and datasets on geoscience knowledge understanding and utilization.We open-source all the training data and K2 model checkpoints at https://github.com/davendw49/k2.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\J2HS3G5Q\Deng et al. - 2023 - K2 A Foundation Language Model for Geoscience Kno.pdf}
}

@misc{devlinBERTPretrainingDeep2019,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  number = {arXiv:1810.04805},
  eprint = {1810.04805},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1810.04805},
  url = {http://arxiv.org/abs/1810.04805},
  urldate = {2023-10-09},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\G4I8TCLX\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf;C\:\\Users\\oskar\\Zotero\\storage\\AFC5RD5Z\\1810.html}
}

@inproceedings{dingMGeoMultiModalGeographic2023,
  title = {{{MGeo}}: {{Multi-Modal Geographic Pre-Training Method}}},
  shorttitle = {{{MGeo}}},
  booktitle = {Proceedings of the 46th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Ding, Ruixue and Chen, Boli and Xie, Pengjun and Huang, Fei and Li, Xin and Zhang, Qiang and Xu, Yao},
  year = {2023},
  month = jul,
  eprint = {2301.04283},
  primaryclass = {cs},
  pages = {185--194},
  doi = {10.1145/3539618.3591728},
  url = {http://arxiv.org/abs/2301.04283},
  urldate = {2023-10-09},
  abstract = {As a core task in location-based services (LBS) (e.g., navigation maps), query and point of interest (POI) matching connects users' intent with real-world geographic information. Recently, pre-trained models (PTMs) have made advancements in many natural language processing (NLP) tasks. Generic text-based PTMs do not have enough geographic knowledge for query-POI matching. To overcome this limitation, related literature attempts to employ domain-adaptive pre-training based on geo-related corpus. However, a query generally contains mentions of multiple geographic objects, such as nearby roads and regions of interest (ROIs). The geographic context (GC), i.e., these diverse geographic objects and their relationships, is therefore pivotal to retrieving the most relevant POI. Single-modal PTMs can barely make use of the important GC and therefore have limited performance. In this work, we propose a novel query-POI matching method Multi-modal Geographic language model (MGeo), which comprises a geographic encoder and a multi-modal interaction module. MGeo represents GC as a new modality and is able to fully extract multi-modal correlations for accurate query-POI matching. Besides, there is no publicly available benchmark for this topic. In order to facilitate further research, we build a new open-source large-scale benchmark Geographic TExtual Similarity (GeoTES). The POIs come from an open-source geographic information system (GIS). The queries are manually generated by annotators to prevent privacy issues. Compared with several strong baselines, the extensive experiment results and detailed ablation analyses on GeoTES demonstrate that our proposed multi-modal pre-training method can significantly improve the query-POI matching capability of generic PTMs, even when the queries' GC is not provided. Our code and dataset are publicly available at https://github.com/PhantomGrapes/MGeo.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\T88ZJGFR\\Ding et al. - 2023 - MGeo Multi-Modal Geographic Pre-Training Method.pdf;C\:\\Users\\oskar\\Zotero\\storage\\EI2TW5EE\\2301.html}
}

@misc{esRAGASAutomatedEvaluation2023,
  title = {{{RAGAS}}: {{Automated Evaluation}} of {{Retrieval Augmented Generation}}},
  shorttitle = {{{RAGAS}}},
  author = {Es, Shahul and James, Jithin and {Espinosa-Anke}, Luis and Schockaert, Steven},
  year = {2023},
  month = sep,
  number = {arXiv:2309.15217},
  eprint = {2309.15217},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2309.15217},
  urldate = {2023-10-06},
  abstract = {We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems are composed of a retrieval and an LLM based generation module, and provide LLMs with knowledge from a reference textual database, which enables them to act as a natural language layer between a user and textual databases, reducing the risk of hallucinations. Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself. With RAGAs, we put forward a suite of metrics which can be used to evaluate these different dimensions {\textbackslash}textit\{without having to rely on ground truth human annotations\}. We posit that such a framework can crucially contribute to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\VJSXZLN9\\Es et al. - 2023 - RAGAS Automated Evaluation of Retrieval Augmented.pdf;C\:\\Users\\oskar\\Zotero\\storage\\NM8DNR5S\\2309.html}
}

@misc{evchakiVectorDatabase2023,
  title = {Vector {{Database}}},
  author = {{evchaki}},
  year = {2023},
  month = nov,
  url = {https://learn.microsoft.com/en-us/semantic-kernel/memories/vector-db},
  urldate = {2023-12-11},
  abstract = {Vector Database},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\VG2JUSU5\vector-db.html}
}

@misc{fanLargeLanguageModels2023,
  title = {Large {{Language Models}} for {{Software Engineering}}: {{Survey}} and {{Open Problems}}},
  shorttitle = {Large {{Language Models}} for {{Software Engineering}}},
  author = {Fan, Angela and Gokkaya, Beliz and Harman, Mark and Lyubarskiy, Mitya and Sengupta, Shubho and Yoo, Shin and Zhang, Jie M.},
  year = {2023},
  month = oct,
  number = {arXiv:2310.03533},
  eprint = {2310.03533},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2310.03533},
  url = {http://arxiv.org/abs/2310.03533},
  urldate = {2023-10-10},
  abstract = {This paper provides a survey of the emerging area of Large Language Models (LLMs) for Software Engineering (SE). It also sets out open research challenges for the application of LLMs to technical problems faced by software engineers. LLMs' emergent properties bring novelty and creativity with applications right across the spectrum of Software Engineering activities including coding, design, requirements, repair, refactoring, performance improvement, documentation and analytics. However, these very same emergent properties also pose significant technical challenges; we need techniques that can reliably weed out incorrect solutions, such as hallucinations. Our survey reveals the pivotal role that hybrid techniques (traditional SE plus LLMs) have to play in the development and deployment of reliable, efficient and effective LLM-based SE.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Software Engineering},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\6TMJQ6P2\\Fan et al. - 2023 - Large Language Models for Software Engineering Su.pdf;C\:\\Users\\oskar\\Zotero\\storage\\ZBKRCYEV\\2310.html}
}

@article{firatWhatIfGPT42023,
  title = {What If {{GPT4 Became Autonomous}}: {{The Auto-GPT Project}} and {{Use Cases}}},
  shorttitle = {What If {{GPT4 Became Autonomous}}},
  author = {Firat, Mehmet and Kuleli, Saniye},
  year = {2023},
  month = may,
  journal = {Journal of Emerging Computer Technologies},
  volume = {3},
  number = {1},
  pages = {1--6},
  publisher = {{Izmir Academy Association}},
  issn = {2757-8267},
  doi = {10.57020/ject.1297961},
  url = {https://dergipark.org.tr/en/pub/ject/issue/77437/1297961},
  urldate = {2023-12-06},
  abstract = {Auto-GPT is a product of an experimental project that makes the use of GPT-4 autonomous. Notably, Auto-GPT emerged and spread rapidly, while the echo of OpenAI's ChatGPT continues. However, there are insufficient studies on this new application in related literature. The purpose of this exploratory case study was to explore the different use cases and experiences of Auto-GPT users. For this purpose, 16 users with an Auto-GPT experience on the GitHub platform were interviewed. Thematic content analysis was performed on the qualitative data. AutoGPT experiences of users can be characterized by learning programs, autonomous applications, conducting research, and writing reports. The results of this study showed that content creation is the most important purpose of using Auto-GPT. As independent research functions of Auto-GPT, users also emphasize data summarization and information organization. However, the participants also pointed out the token limit (inefficiency), forgetting generated tools, and iteration as some prominent limitations of Auto-GPT. It is possible to say that Auto-GPT has a high potential to use in also in educational purpose, but it is still in the development stage.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\D23BL9DX\Firat and Kuleli̇ - What if GPT4 Became Autonomous The Auto-GPT Proje.pdf}
}

@inproceedings{gamanReportVarDialEvaluation2020,
  title = {A {{Report}} on the {{VarDial Evaluation Campaign}} 2020},
  booktitle = {Proceedings of the 7th {{Workshop}} on {{NLP}} for {{Similar Languages}}, {{Varieties}} and {{Dialects}}},
  author = {Gaman, Mihaela and Hovy, Dirk and Ionescu, Radu Tudor and Jauhiainen, Heidi and Jauhiainen, Tommi and Lind{\'e}n, Krister and Ljube{\v s}i{\'c}, Nikola and Partanen, Niko and Purschke, Christoph and Scherrer, Yves and Zampieri, Marcos},
  year = {2020},
  month = dec,
  pages = {1--14},
  publisher = {{International Committee on Computational Linguistics (ICCL)}},
  address = {{Barcelona, Spain (Online)}},
  url = {https://aclanthology.org/2020.vardial-1.1},
  urldate = {2023-10-16},
  abstract = {This paper presents the results of the VarDial Evaluation Campaign 2020 organized as part of the seventh workshop on Natural Language Processing (NLP) for Similar Languages, Varieties and Dialects (VarDial), co-located with COLING 2020. The campaign included three shared tasks each focusing on a different challenge of language and dialect identification: Romanian Dialect Identification (RDI), Social Media Variety Geolocation (SMG), and Uralic Language Identification (ULI). The campaign attracted 30 teams who enrolled to participate in one or multiple shared tasks and 14 of them submitted runs across the three shared tasks. Finally, 11 papers describing participating systems are published in the VarDial proceedings and referred to in this report.},
  file = {C:\Users\oskar\Zotero\storage\8UCGMNYC\Gaman et al. - 2020 - A Report on the VarDial Evaluation Campaign 2020.pdf}
}

@techreport{geminiteamGeminiFamilyHighly2023,
  title = {Gemini: {{A Family}} of {{Highly Capable Multimodal Models}}},
  author = {{Gemini Team} and {Google}},
  year = {2023},
  month = dec,
  url = {https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf},
  urldate = {2023-12-07},
  file = {C:\Users\oskar\Zotero\storage\9EWCSJ9W\gemini_1_report.pdf}
}

@inproceedings{gramackiSRAIStandardizationGeospatial2023,
  title = {{{SRAI}}: {{Towards Standardization}} of {{Geospatial AI}}},
  shorttitle = {{{SRAI}}},
  booktitle = {Proceedings of the 6th {{ACM SIGSPATIAL International Workshop}} on {{AI}} for {{Geographic Knowledge Discovery}}},
  author = {Gramacki, Piotr and Le{\'s}niara, Kacper and Raczycki, Kamil and Wo{\'z}niak, Szymon and Przymus, Marcin and Szyma{\'n}ski, Piotr},
  year = {2023},
  month = nov,
  eprint = {2310.13098},
  primaryclass = {cs},
  pages = {43--52},
  doi = {10.1145/3615886.3627740},
  url = {http://arxiv.org/abs/2310.13098},
  urldate = {2023-12-06},
  abstract = {Spatial Representations for Artificial Intelligence (srai) is a Python library for working with geospatial data. The library can download geospatial data, split a given area into micro-regions using multiple algorithms and train an embedding model using various architectures. It includes baseline models as well as more complex methods from published works. Those capabilities make it possible to use srai in a complete pipeline for geospatial task solving. The proposed library is the first step to standardize the geospatial AI domain toolset. It is fully open-source and published under Apache 2.0 licence.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\YPMEFUCI\\Gramacki et al. - 2023 - SRAI Towards Standardization of Geospatial AI.pdf;C\:\\Users\\oskar\\Zotero\\storage\\FFH2L2AJ\\2310.html}
}

@misc{guoRetrievalaugmentedGPT35based2023,
  title = {Retrieval-Augmented {{GPT-3}}.5-Based {{Text-to-SQL Framework}} with {{Sample-aware Prompting}} and {{Dynamic Revision Chain}}},
  author = {Guo, Chunxi and Tian, Zhiliang and Tang, Jintao and Li, Shasha and Wen, Zhihua and Wang, Kaixuan and Wang, Ting},
  year = {2023},
  month = sep,
  number = {arXiv:2307.05074},
  eprint = {2307.05074},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2307.05074},
  urldate = {2023-10-06},
  abstract = {Text-to-SQL aims at generating SQL queries for the given natural language questions and thus helping users to query databases. Prompt learning with large language models (LLMs) has emerged as a recent approach, which designs prompts to lead LLMs to understand the input question and generate the corresponding SQL. However, it faces challenges with strict SQL syntax requirements. Existing work prompts the LLMs with a list of demonstration examples (i.e. question-SQL pairs) to generate SQL, but the fixed prompts can hardly handle the scenario where the semantic gap between the retrieved demonstration and the input question is large. In this paper, we propose a retrieval-augmented prompting method for a LLM-based Text-to-SQL framework, involving sample-aware prompting and a dynamic revision chain. Our approach incorporates sample-aware demonstrations, which include the composition of SQL operators and fine-grained information related to the given question. To retrieve questions sharing similar intents with input questions, we propose two strategies for assisting retrieval. Firstly, we leverage LLMs to simplify the original questions, unifying the syntax and thereby clarifying the users' intentions. To generate executable and accurate SQLs without human intervention, we design a dynamic revision chain which iteratively adapts fine-grained feedback from the previously generated SQL. Experimental results on three Text-to-SQL benchmarks demonstrate the superiority of our method over strong baseline models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Databases,Computer Science - Information Retrieval},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\H52FCBE6\\Guo et al. - 2023 - Retrieval-augmented GPT-3.5-based Text-to-SQL Fram.pdf;C\:\\Users\\oskar\\Zotero\\storage\\MBQAMJC3\\2307.html}
}

@article{harrisEmpowermentMarginalizationCommunityintegrated1998,
  title = {Empowerment, {{Marginalization}}, and "{{Community-integrated}}" {{GIS}}},
  author = {Harris, Trevor and Weiner, Daniel},
  year = {1998},
  month = jan,
  journal = {Cartography and Geographic Information Systems},
  volume = {25},
  number = {2},
  pages = {67--76},
  publisher = {{Taylor \& Francis}},
  issn = {1050-9844},
  doi = {10.1559/152304098782594580},
  url = {https://doi.org/10.1559/152304098782594580},
  urldate = {2023-12-02},
  abstract = {The "GIS and Society" literature has raised a number of critical issues concerning the political economy and epistemology of geographical information systems (GIS) and the politics and power relations associated with their use. Recently, attention has focused on the potential for GIS to help empower communities. This paper reviews the GIS and Society debate. Case studies of public participation GIS are reviewed. The GIS-empowerment-marginalization nexus is addressed through the concept of community-integrated GIS. It is argued that GIS is a contradictory technology that simultaneously marginalizes and empowers people and communities. As a result, the societal impacts of GIS are contingent upon particular configurations of place-based historical, socio-economic, political, and technological conditions.},
  file = {C:\Users\oskar\Zotero\storage\XMVX3NYP\Harris and Weiner - 1998 - Empowerment, Marginalization, and Community-integ.pdf}
}

@misc{hendrycksMeasuringMassiveMultitask2021,
  title = {Measuring {{Massive Multitask Language Understanding}}},
  author = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  year = {2021},
  month = jan,
  number = {arXiv:2009.03300},
  eprint = {2009.03300},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2009.03300},
  url = {http://arxiv.org/abs/2009.03300},
  urldate = {2023-10-30},
  abstract = {We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\4AN4PUCX\\Hendrycks et al. - 2021 - Measuring Massive Multitask Language Understanding.pdf;C\:\\Users\\oskar\\Zotero\\storage\\SSIQIZYR\\2009.html}
}

@misc{holmesSpatioTemporalAssetCatalogs2021,
  title = {{{SpatioTemporal Asset Catalogs}} and the {{Open Geospatial Consortium}}},
  author = {Holmes, Chris},
  year = {2021},
  month = jan,
  journal = {Radiant Earth Insights},
  url = {https://medium.com/radiant-earth-insights/spatiotemporal-asset-catalogs-and-the-open-geospatial-consortium-659538dce5c7},
  urldate = {2023-10-23},
  abstract = {As SpatioTemporal Asset Catalog (STAC) specification matures one of the more frequent questions we get asked is the relationship between{\ldots}},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\SU8TIBLC\spatiotemporal-asset-catalogs-and-the-open-geospatial-consortium-659538dce5c7.html}
}

@inproceedings{huangERNIEGeoLGeographyandLanguagePretrained2022,
  title = {{{ERNIE-GeoL}}: {{A Geography-and-Language Pre-trained Model}} and Its {{Applications}} in {{Baidu Maps}}},
  shorttitle = {{{ERNIE-GeoL}}},
  booktitle = {Proceedings of the 28th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Huang, Jizhou and Wang, Haifeng and Sun, Yibo and Shi, Yunsheng and Huang, Zhengjie and Zhuo, An and Feng, Shikun},
  year = {2022},
  month = aug,
  series = {{{KDD}} '22},
  pages = {3029--3039},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3534678.3539021},
  url = {https://dl.acm.org/doi/10.1145/3534678.3539021},
  urldate = {2023-10-09},
  abstract = {Pre-trained models (PTMs) have become a fundamental backbone for downstream tasks in natural language processing and computer vision. Despite initial gains that were obtained by applying generic PTMs to geo-related tasks at Baidu Maps, a clear performance plateau over time was observed. One of the main reasons for this plateau is the lack of readily available geographic knowledge in generic PTMs. To address this problem, in this paper, we present ERNIE-GeoL, which is a geography-and-language pre-trained model designed and developed for improving the geo-related tasks at Baidu Maps. ERNIE-GeoL is elaborately designed to learn a universal representation of geography-language by pre-training on large-scale data generated from a heterogeneous graph that contains abundant geographic knowledge. Extensive quantitative and qualitative experiments conducted on large-scale real-world datasets demonstrate the superiority and effectiveness of ERNIE-GeoL. ERNIE-GeoL has already been deployed in production at Baidu Maps since April 2021, which significantly benefits the performance of various downstream tasks. This demonstrates that ERNIE-GeoL can serve as a fundamental backbone for a wide range of geo-related tasks.},
  isbn = {978-1-4503-9385-0},
  keywords = {graph neural network,heterogeneous graph,pre-training},
  file = {C:\Users\oskar\Zotero\storage\AIMX8FHN\Huang et al. - 2022 - ERNIE-GeoL A Geography-and-Language Pre-trained M.pdf}
}

@article{huangLearningUrbanRegion2023,
  title = {Learning Urban Region Representations with {{POIs}} and Hierarchical Graph Infomax},
  author = {Huang, Weiming and Zhang, Daokun and Mai, Gengchen and Guo, Xu and Cui, Lizhen},
  year = {2023},
  month = feb,
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume = {196},
  pages = {134--145},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2022.11.021},
  url = {https://www.sciencedirect.com/science/article/pii/S0924271622003148},
  urldate = {2023-10-09},
  abstract = {We present the hierarchical graph infomax (HGI) approach for learning urban region representations (vector embeddings) with points-of-interest (POIs) in a fully unsupervised manner, which can be used in various downstream tasks. Specifically, HGI comprises several key steps: (1) training category embeddings as the initial features of POIs; (2) interconnecting POIs with a graph structure and performing graph convolution to capture the uniqueness of each POI based on its spatial context; (3) aggregating POIs to the regional level using multi-head attention mechanisms, to consider the multi-faceted influence from POIs to regions; (4) performing graph convolution at the regional level to generate region representations, to incorporate the similarities between adjacent regions; (5) aggregating region representations to produce an embedding at the city level. The model is finally trained through maximizing the mutual information among the POI {\textendash} region {\textendash} city hierarchy, which facilitates the information from local (POIs) and global (city) scales flowing to the learned region representations, making them both locally and globally relevant. We perform extensive experiments on three downstream tasks, i.e., estimating urban functional distributions, population density, and housing price, in the study areas of Xiamen Island and Shenzhen, China. The results indicate that HGI considerably outperforms several competitive baselines in all three tasks, which proves that HGI could produce meaningful and effective region representations. In addition, the learned region representations based on POIs can potentially be used for reinforcing data representations from other modalities, e.g., remote sensing data. The implementation of HGI can be found at https://github.com/RightBank/HGI.},
  keywords = {Hierarchical graph infomax,Housing price prediction,Point-of-interest,Population density estimation,Unsupervised learning,Urban function inference,Urban region embedding},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\G93HDPLT\\Huang et al. - 2023 - Learning urban region representations with POIs an.pdf;C\:\\Users\\oskar\\Zotero\\storage\\QJ7NV2IS\\S0924271622003148.html}
}

@misc{huggingfacePerplexityFixedlengthModels,
  title = {Perplexity of Fixed-Length Models},
  author = {{Hugging Face}},
  url = {https://huggingface.co/docs/transformers/perplexity},
  urldate = {2023-12-09},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {C:\Users\oskar\Zotero\storage\YS2BKABR\perplexity.html}
}

@incollection{hughesTechnologicalMomentum1994,
  title = {Technological Momentum},
  booktitle = {Does {{Technology Drive History}}? {{The Dilemma}} of {{Technological Determinism}}},
  author = {Hughes, T.},
  editor = {Marx, L. and Smith, M.R.},
  year = {1994},
  pages = {101--113},
  publisher = {{MIT Press}},
  file = {C:\Users\oskar\Zotero\storage\WFE96NJI\Hughes - 1994 - Technological momentum.pdf}
}

@misc{hulbertExploringChatGPTCode2023,
  title = {Exploring {{ChatGPT Code Interpreter}}},
  author = {Hulbert, Dave},
  year = {2023},
  month = aug,
  journal = {Medium},
  url = {https://medium.com/@dave1010/exploring-chatgpt-code-interpreter-5d0872d67058},
  urldate = {2023-12-03},
  abstract = {ChatGPT Code Interpreter is more than just a Python tool. With a bit of exploration, it can run JavaScript, PHP, process videos and more.},
  langid = {english}
}

@misc{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and {Allen-Zhu}, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  year = {2021},
  month = oct,
  number = {arXiv:2106.09685},
  eprint = {2106.09685},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2106.09685},
  url = {http://arxiv.org/abs/2106.09685},
  urldate = {2023-10-09},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\FBDIM7D6\\Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf;C\:\\Users\\oskar\\Zotero\\storage\\HPY45HFE\\2106.html}
}

@misc{jiangActiveRetrievalAugmented2023,
  title = {Active {{Retrieval Augmented Generation}}},
  author = {Jiang, Zhengbao and Xu, Frank F. and Gao, Luyu and Sun, Zhiqing and Liu, Qian and {Dwivedi-Yu}, Jane and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  year = {2023},
  month = oct,
  number = {arXiv:2305.06983},
  eprint = {2305.06983},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.06983},
  url = {http://arxiv.org/abs/2305.06983},
  urldate = {2023-12-06},
  abstract = {Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\YQPVQ4FH\\Jiang et al. - 2023 - Active Retrieval Augmented Generation.pdf;C\:\\Users\\oskar\\Zotero\\storage\\PY98V3XJ\\2305.html}
}

@misc{karpasMRKLSystemsModular2022,
  title = {{{MRKL Systems}}: {{A}} Modular, Neuro-Symbolic Architecture That Combines Large Language Models, External Knowledge Sources and Discrete Reasoning},
  shorttitle = {{{MRKL Systems}}},
  author = {Karpas, Ehud and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and {Leyton-Brown}, Kevin and Muhlgay, Dor and Rozen, Noam and Schwartz, Erez and Shachaf, Gal and {Shalev-Shwartz}, Shai and Shashua, Amnon and Tenenholtz, Moshe},
  year = {2022},
  month = may,
  number = {arXiv:2205.00445},
  eprint = {2205.00445},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2205.00445},
  urldate = {2023-11-01},
  abstract = {Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language (MRKL, pronounced "miracle") system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs' MRKL system implementation.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\JS8YL74B\\Karpas et al. - 2022 - MRKL Systems A modular, neuro-symbolic architectu.pdf;C\:\\Users\\oskar\\Zotero\\storage\\BICEKTHS\\2205.html}
}

@misc{kearyBestOpenSourceLLMs2023,
  title = {6 {{Best Open-Source LLMs}} to {{Watch Out For}} in 2024},
  author = {Keary, Tim},
  year = {2023},
  month = oct,
  journal = {Techopedia},
  url = {https://www.techopedia.com/6-best-open-source-llms-to-watch-out-for-in-2024},
  urldate = {2023-10-30},
  abstract = {As the AI industry continues to advance, Techopedia looks at the top 6 open-source large language models (LMMs) to watch in 2024.},
  langid = {american}
}

@misc{killianlucasKillianLucasOpeninterpreter2023,
  title = {{{KillianLucas}}/Open-Interpreter},
  author = {{KillianLucas}},
  year = {2023},
  month = dec,
  url = {https://github.com/KillianLucas/open-interpreter},
  urldate = {2023-12-13},
  abstract = {OpenAI's Code Interpreter in your terminal, running locally},
  copyright = {AGPL-3.0},
  keywords = {chatgpt,gpt-4,interpreter,javascript,nodejs,python,react}
}

@misc{kmetzUnlockingPotentialAI2023,
  title = {Unlocking the {{Potential}} of {{AI Models}} for {{Geospatial Analysis Through Prompt Engineering}}},
  author = {Kmetz, Ryan},
  year = {2023},
  month = oct,
  journal = {Medium},
  url = {https://ryankmetz.medium.com/unlocking-the-potential-of-ai-models-for-geospatial-analysis-through-prompt-engineering-fd7a78d20352},
  urldate = {2023-11-13},
  abstract = {Prompt engine\-ering is a crucial discipline in the ge\-ospatial field.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\J9GBTRDV\unlocking-the-potential-of-ai-models-for-geospatial-analysis-through-prompt-engineering-fd7a78d.html}
}

@techreport{kommunal-ogmoderniseringsdepartementetNationalGeospatialStrategy2018,
  type = {{Strategy}},
  title = {{National geospatial strategy toward 2025 - Everything happens somewhere}},
  author = {{Kommunal- og moderniseringsdepartementet}},
  year = {2018},
  month = nov,
  address = {{Oslo, Norway}},
  institution = {{Kommunal- og moderniseringsdepartementet}},
  url = {https://www.regjeringen.no/no/dokumenter/nasjonal-geodatastrategi---alt-skjer-et-sted/id2617560/},
  langid = {Norwegian, English},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\6APDTJLW\\_.pdf;C\:\\Users\\oskar\\Zotero\\storage\\6PE8F7YX\\en_nasjonal_geodatastrategi.pdf}
}

@misc{kumarWhatArePeople2023a,
  title = {What Are People Asking to {{ChatGPT}}?},
  author = {Kumar, Varun},
  year = {2023},
  month = may,
  journal = {Medium},
  url = {https://varunon9.medium.com/what-are-people-asking-to-chatgpt-f5f324a6cc27},
  urldate = {2023-10-25},
  abstract = {What's hot these days? ``Spam calls'' on WhatsApp? Crisis in Pakistan? Election in Karnataka?},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\I2LWCNWM\what-are-people-asking-to-chatgpt-f5f324a6cc27.html}
}

@misc{LargeLanguageModel,
  title = {Large {{Language Model Evaluation}} in 2023: 5 {{Methods}}},
  shorttitle = {Large {{Language Model Evaluation}} in 2023},
  url = {https://research.aimultiple.com/large-language-model-evaluation/},
  urldate = {2023-12-16},
  abstract = {Large Language Models (LLMs) have expanded rapidly and may lead the AI transformation. This makes LLM evaluation important more than ever.},
  langid = {american}
}

@inproceedings{lewisRetrievalAugmentedGenerationKnowledgeIntensive2020,
  title = {Retrieval-{{Augmented Generation}} for {{Knowledge-Intensive NLP Tasks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  year = {2020},
  volume = {33},
  pages = {9459--9474},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html},
  urldate = {2023-12-06},
  abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
  file = {C:\Users\oskar\Zotero\storage\C9CZL5M6\Lewis et al. - 2020 - Retrieval-Augmented Generation for Knowledge-Inten.pdf}
}

@misc{liAPIBankComprehensiveBenchmark2023,
  title = {{{API-Bank}}: {{A Comprehensive Benchmark}} for {{Tool-Augmented LLMs}}},
  shorttitle = {{{API-Bank}}},
  author = {Li, Minghao and Zhao, Yingxiu and Yu, Bowen and Song, Feifan and Li, Hangyu and Yu, Haiyang and Li, Zhoujun and Huang, Fei and Li, Yongbin},
  year = {2023},
  month = oct,
  number = {arXiv:2304.08244},
  eprint = {2304.08244},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2304.08244},
  url = {http://arxiv.org/abs/2304.08244},
  urldate = {2023-12-11},
  abstract = {Recent research has demonstrated that Large Language Models (LLMs) can enhance their capabilities by utilizing external tools. However, three pivotal questions remain unanswered: (1) How effective are current LLMs in utilizing tools? (2) How can we enhance LLMs' ability to utilize tools? (3) What obstacles need to be overcome to leverage tools? To address these questions, we introduce API-Bank, a groundbreaking benchmark, specifically designed for tool-augmented LLMs. For the first question, we develop a runnable evaluation system consisting of 73 API tools. We annotate 314 tool-use dialogues with 753 API calls to assess the existing LLMs' capabilities in planning, retrieving, and calling APIs. For the second question, we construct a comprehensive training set containing 1,888 tool-use dialogues from 2,138 APIs spanning 1,000 distinct domains. Using this dataset, we train Lynx, a tool-augmented LLM initialized from Alpaca. Experimental results demonstrate that GPT-3.5 exhibits improved tool utilization compared to GPT-3, while GPT-4 excels in planning. However, there is still significant potential for further improvement. Moreover, Lynx surpasses Alpaca's tool utilization performance by more than 26 pts and approaches the effectiveness of GPT-3.5. Through error analysis, we highlight the key challenges for future research in this field to answer the third question.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\ACGLRV7J\\Li et al. - 2023 - API-Bank A Comprehensive Benchmark for Tool-Augme.pdf;C\:\\Users\\oskar\\Zotero\\storage\\6IIAZDGD\\2304.html}
}

@misc{liAutonomousGISNextgeneration2023,
  title = {Autonomous {{GIS}}: The next-Generation {{AI-powered GIS}}},
  shorttitle = {Autonomous {{GIS}}},
  author = {Li, Zhenlong and Ning, Huan},
  year = {2023},
  month = may,
  number = {arXiv:2305.06453},
  eprint = {2305.06453},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.06453},
  url = {http://arxiv.org/abs/2305.06453},
  urldate = {2023-10-04},
  abstract = {Large Language Models (LLMs), such as ChatGPT, demonstrate a strong understanding of human natural language and have been explored and applied in various fields, including reasoning, creative writing, code generation, translation, and information retrieval. By adopting LLM as the reasoning core, we introduce Autonomous GIS as an AI-powered geographic information system (GIS) that leverages the LLM's general abilities in natural language understanding, reasoning, and coding for addressing spatial problems with automatic spatial data collection, analysis, and visualization. We envision that autonomous GIS will need to achieve five autonomous goals: self-generating, self-organizing, self-verifying, self-executing, and self-growing. We developed a prototype system called LLM-Geo using the GPT-4 API in a Python environment, demonstrating what an autonomous GIS looks like and how it delivers expected results without human intervention using three case studies. For all case studies, LLM-Geo was able to return accurate results, including aggregated numbers, graphs, and maps, significantly reducing manual operation time. Although still in its infancy and lacking several important modules such as logging and code testing, LLM-Geo demonstrates a potential path toward the next-generation AI-powered GIS. We advocate for the GIScience community to dedicate more effort to the research and development of autonomous GIS, making spatial analysis easier, faster, and more accessible to a broader audience.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\F2SMY58Q\\Li and Ning - 2023 - Autonomous GIS the next-generation AI-powered GIS.pdf;C\:\\Users\\oskar\\Zotero\\storage\\JRUTEB6E\\2305.html}
}

@inproceedings{liDiversityPromotingObjectiveFunction2016,
  title = {A {{Diversity-Promoting Objective Function}} for {{Neural Conversation Models}}},
  booktitle = {Proceedings of the 2016 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
  editor = {Knight, Kevin and Nenkova, Ani and Rambow, Owen},
  year = {2016},
  month = jun,
  pages = {110--119},
  publisher = {{Association for Computational Linguistics}},
  address = {{San Diego, California}},
  doi = {10.18653/v1/N16-1014},
  url = {https://aclanthology.org/N16-1014},
  urldate = {2023-12-09},
  file = {C:\Users\oskar\Zotero\storage\N9UYMECF\Li et al. - 2016 - A Diversity-Promoting Objective Function for Neura.pdf}
}

@inproceedings{linROUGEPackageAutomatic2004,
  title = {{{ROUGE}}: {{A Package}} for {{Automatic Evaluation}} of {{Summaries}}},
  shorttitle = {{{ROUGE}}},
  booktitle = {Text {{Summarization Branches Out}}},
  author = {Lin, Chin-Yew},
  year = {2004},
  month = jul,
  pages = {74--81},
  publisher = {{Association for Computational Linguistics}},
  address = {{Barcelona, Spain}},
  url = {https://aclanthology.org/W04-1013},
  urldate = {2023-12-07},
  file = {C:\Users\oskar\Zotero\storage\DR2YMCEH\Lin - 2004 - ROUGE A Package for Automatic Evaluation of Summa.pdf}
}

@misc{maedaAutoGenAgentsMeet2023,
  title = {{{AutoGen Agents Meet Semantic Kernel}}},
  author = {Maeda, John},
  year = {2023},
  month = nov,
  journal = {Semantic Kernel},
  url = {https://devblogs.microsoft.com/semantic-kernel/autogen-agents-meet-semantic-kernel/},
  urldate = {2023-12-11},
  abstract = {In this blog post, we show you how you can use Semantic Kernel with~AutoGen, a Microsoft Research project that shows the potential of using multiple agents together. With AutoGen, Microsoft research has shown that multiple agents can be better than one.},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\VN7STXYH\autogen-agents-meet-semantic-kernel.html}
}

@article{maehlumSOSI2023,
  title = {{SOSI}},
  author = {M{\ae}hlum, Lars and R{\o}d, Jan Ketil},
  year = {2023},
  month = jun,
  journal = {Store norske leksikon},
  url = {https://snl.no/SOSI},
  urldate = {2023-10-23},
  abstract = {SOSI er et norsk filformat for lagring og utveksling av geodata. F{\o}rste versjon av SOSI kom i 1987 og har siden n{\ae}rmet seg internasjonale standarder. SOSI er vedtatt norsk standard for etablering og leveranse av digitale geografiske data, og administreres av Statens kartverk. I et SOSI-datasett er terrengets punkter, linjer og flater representert ved sine koordinater og klassifisert i ulike objekttyper i henhold til standardens objektkatalog.},
  copyright = {fri},
  langid = {norsk},
  keywords = {Geomatikk},
  file = {C:\Users\oskar\Zotero\storage\2AIFZDZQ\SOSI.html}
}

@misc{mahamudDistributionalDataAugmentation2023,
  title = {Distributional {{Data Augmentation Methods}} for {{Low Resource Language}}},
  author = {Mahamud, Mosleh and Lee, Zed and Samsten, Isak},
  year = {2023},
  month = sep,
  number = {arXiv:2309.04862},
  eprint = {2309.04862},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2309.04862},
  url = {http://arxiv.org/abs/2309.04862},
  urldate = {2023-10-06},
  abstract = {Text augmentation is a technique for constructing synthetic data from an under-resourced corpus to improve predictive performance. Synthetic data generation is common in numerous domains. However, recently text augmentation has emerged in natural language processing (NLP) to improve downstream tasks. One of the current state-of-the-art text augmentation techniques is easy data augmentation (EDA), which augments the training data by injecting and replacing synonyms and randomly permuting sentences. One major obstacle with EDA is the need for versatile and complete synonym dictionaries, which cannot be easily found in low-resource languages. To improve the utility of EDA, we propose two extensions, easy distributional data augmentation (EDDA) and type specific similar word replacement (TSSR), which uses semantic word context information and part-of-speech tags for word replacement and augmentation. In an extensive empirical evaluation, we show the utility of the proposed methods, measured by F1 score, on two representative datasets in Swedish as an example of a low-resource language. With the proposed methods, we show that augmented data improve classification performances in low-resource settings.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\G5UG8NBG\\Mahamud et al. - 2023 - Distributional Data Augmentation Methods for Low R.pdf;C\:\\Users\\oskar\\Zotero\\storage\\VISTCABC\\2309.html}
}

@misc{maiOpportunitiesChallengesFoundation2023,
  title = {On the {{Opportunities}} and {{Challenges}} of {{Foundation Models}} for {{Geospatial Artificial Intelligence}}},
  author = {Mai, Gengchen and Huang, Weiming and Sun, Jin and Song, Suhang and Mishra, Deepak and Liu, Ninghao and Gao, Song and Liu, Tianming and Cong, Gao and Hu, Yingjie and Cundy, Chris and Li, Ziyuan and Zhu, Rui and Lao, Ni},
  year = {2023},
  month = apr,
  number = {arXiv:2304.06798},
  eprint = {2304.06798},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2304.06798},
  urldate = {2023-10-05},
  abstract = {Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial subdomains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, these task-agnostic LLMs can outperform task-specific fully-supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image-based urban noise intensity classification, and remote sensing image scene classification), existing foundation models still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing a FM for GeoAI is to address the multimodality nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal foundation model which can reason over various types of geospatial data through geospatial alignments. We conclude this paper by discussing the unique risks and challenges to develop such a model for GeoAI.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,I.2.0,I.2.10,I.2.4,I.2.7,I.5.1},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\KR8QU4W7\\Mai et al. - 2023 - On the Opportunities and Challenges of Foundation .pdf;C\:\\Users\\oskar\\Zotero\\storage\\LIMFU3ZQ\\Mai et al. - 2023 - On the Opportunities and Challenges of Foundation .pdf;C\:\\Users\\oskar\\Zotero\\storage\\F5ULIY86\\2304.html}
}

@misc{maiOpportunitiesChallengesFoundation2023a,
  title = {On the {{Opportunities}} and {{Challenges}} of {{Foundation Models}} for {{Geospatial Artificial Intelligence}}},
  author = {Mai, Gengchen and Huang, Weiming and Sun, Jin and Song, Suhang and Mishra, Deepak and Liu, Ninghao and Gao, Song and Liu, Tianming and Cong, Gao and Hu, Yingjie and Cundy, Chris and Li, Ziyuan and Zhu, Rui and Lao, Ni},
  year = {2023},
  month = apr,
  journal = {arXiv.org},
  url = {https://arxiv.org/abs/2304.06798v1},
  urldate = {2023-10-09},
  abstract = {Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial subdomains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, these task-agnostic LLMs can outperform task-specific fully-supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image-based urban noise intensity classification, and remote sensing image scene classification), existing foundation models still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing a FM for GeoAI is to address the multimodality nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal foundation model which can reason over various types of geospatial data through geospatial alignments. We conclude this paper by discussing the unique risks and challenges to develop such a model for GeoAI.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\JPKCU689\Mai et al. - 2023 - On the Opportunities and Challenges of Foundation .pdf}
}

@article{mardalNasjonalStrategiVidereutvikling2015,
  title = {{Nasjonal strategi for videreutvikling av SOSI}},
  author = {Mardal, Gerd and Borreb, Morten and Christensen, Lars and Jetlund, Knut and Ryghaug, Per and Hokstad, Inger},
  year = {2015},
  month = oct,
  langid = {norsk},
  file = {C:\Users\oskar\Zotero\storage\SQ4W6NP2\Mardal et al. - Nasjonal strategi for videreutvikling av SOSI.pdf}
}

@misc{martineauWhatRetrievalaugmentedGeneration2023,
  title = {What Is Retrieval-Augmented Generation?},
  author = {Martineau, Kim},
  year = {2023},
  month = aug,
  url = {https://research.ibm.com/blog/retrieval-augmented-generation-RAG},
  urldate = {2023-10-06},
  file = {C:\Users\oskar\Zotero\storage\4IXQ75XY\retrieval-augmented-generation-RAG.html}
}

@incollection{masoGeospatialWebServices2022,
  title = {Geospatial {{Web Services}}},
  booktitle = {Springer {{Handbook}} of {{Geographic Information}}},
  author = {Mas{\'o}, Joan},
  editor = {Kresse, Wolfgang and Danko, David},
  year = {2022},
  series = {Springer {{Handbooks}}},
  pages = {493--530},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-53125-6_16},
  url = {https://doi.org/10.1007/978-3-030-53125-6_16},
  urldate = {2023-10-23},
  abstract = {Geospatial web services are based on the communication networks that connect computers on the Internet. The communication network protocols are structured in layers. Top layers hide the incremental complexity of the heterogeneous hardware. Geospatial web services can be implemented using Hypertext Transfer Protocol (HTTP) to distribute geospatial resources (resource-oriented architecture style) or can be implemented as a~new layer of protocol on top of HTTP (service-oriented architecture style). Geospatial web services separate the application into a~client side that requests information and a~server side that responds to that request, using a~common communication protocol (that specifies the communication language and request and respond formats). These two sides might be developed using different programming languages and might be implemented by several vendors; however they are able to interoperate because they use a~set of well-defined internationally agreed open standards.},
  isbn = {978-3-030-53125-6},
  langid = {english},
  keywords = {communication,geospatial,networks,resources,web services},
  file = {C:\Users\oskar\Zotero\storage\2GU9CWNV\Masó - 2022 - Geospatial Web Services.pdf}
}

@misc{mialonAugmentedLanguageModels2023,
  title = {Augmented {{Language Models}}: A {{Survey}}},
  shorttitle = {Augmented {{Language Models}}},
  author = {Mialon, Gr{\'e}goire and Dess{\`i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and {Dwivedi-Yu}, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
  year = {2023},
  month = feb,
  number = {arXiv:2302.07842},
  eprint = {2302.07842},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2302.07842},
  urldate = {2023-10-05},
  abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\KXD9RICF\\Mialon et al. - 2023 - Augmented Language Models a Survey.pdf;C\:\\Users\\oskar\\Zotero\\storage\\AESC743L\\2302.html}
}

@misc{mirandaCurseLowTask2022,
  title = {The {{Curse}} of {{Low Task Diversity}}: {{On}} the {{Failure}} of {{Transfer Learning}} to {{Outperform MAML}} and {{Their Empirical Equivalence}}},
  shorttitle = {The {{Curse}} of {{Low Task Diversity}}},
  author = {Miranda, Brando and Yu, Patrick and Wang, Yu-Xiong and Koyejo, Sanmi},
  year = {2022},
  month = aug,
  number = {arXiv:2208.01545},
  eprint = {2208.01545},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2208.01545},
  urldate = {2023-12-09},
  abstract = {Recently, it has been observed that a transfer learning solution might be all we need to solve many few-shot learning benchmarks -- thus raising important questions about when and how meta-learning algorithms should be deployed. In this paper, we seek to clarify these questions by 1. proposing a novel metric -- the diversity coefficient -- to measure the diversity of tasks in a few-shot learning benchmark and 2. by comparing Model-Agnostic Meta-Learning (MAML) and transfer learning under fair conditions (same architecture, same optimizer, and all models trained to convergence). Using the diversity coefficient, we show that the popular MiniImageNet and CIFAR-FS few-shot learning benchmarks have low diversity. This novel insight contextualizes claims that transfer learning solutions are better than meta-learned solutions in the regime of low diversity under a fair comparison. Specifically, we empirically find that a low diversity coefficient correlates with a high similarity between transfer learning and MAML learned solutions in terms of accuracy at meta-test time and classification layer similarity (using feature based distance metrics like SVCCA, PWCCA, CKA, and OPD). To further support our claim, we find this meta-test accuracy holds even as the model size changes. Therefore, we conclude that in the low diversity regime, MAML and transfer learning have equivalent meta-test performance when both are compared fairly. We also hope our work inspires more thoughtful constructions and quantitative evaluations of meta-learning benchmarks in the future.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\BDPKAUS5\\Miranda et al. - 2022 - The Curse of Low Task Diversity On the Failure of.pdf;C\:\\Users\\oskar\\Zotero\\storage\\DG22I7AY\\2208.html}
}

@misc{mistralaiMistral7B2023,
  title = {Mistral {{7B}}},
  author = {{Mistral AI}},
  year = {2023},
  month = sep,
  url = {https://mistral.ai/news/announcing-mistral-7b/},
  urldate = {2023-12-07},
  abstract = {The best 7B model to date, Apache 2.0},
  chapter = {news},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\4VXGY5JH\announcing-mistral-7b.html}
}

@misc{mitraOrcaTeachingSmall2023,
  title = {Orca 2: {{Teaching Small Language Models How}} to {{Reason}}},
  shorttitle = {Orca 2},
  author = {Mitra, Arindam and Del Corro, Luciano and Mahajan, Shweti and Codas, Andres and Simoes, Clarisse and Agarwal, Sahaj and Chen, Xuxi and Razdaibiedina, Anastasia and Jones, Erik and Aggarwal, Kriti and Palangi, Hamid and Zheng, Guoqing and Rosset, Corby and Khanpour, Hamed and Awadallah, Ahmed},
  year = {2023},
  month = nov,
  number = {arXiv:2311.11045},
  eprint = {2311.11045},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2311.11045},
  urldate = {2023-12-12},
  abstract = {Orca 1 learns from rich signals, such as explanation traces, allowing it to outperform conventional instruction-tuned models on benchmarks like BigBench Hard and AGIEval. In Orca 2, we continue exploring how improved training signals can enhance smaller LMs' reasoning abilities. Research on training small LMs has often relied on imitation learning to replicate the output of more capable models. We contend that excessive emphasis on imitation may restrict the potential of smaller models. We seek to teach small LMs to employ different solution strategies for different tasks, potentially different from the one used by the larger model. For example, while larger models might provide a direct answer to a complex task, smaller models may not have the same capacity. In Orca 2, we teach the model various reasoning techniques (step-by-step, recall then generate, recall-reason-generate, direct answer, etc.). More crucially, we aim to help the model learn to determine the most effective solution strategy for each task. We evaluate Orca 2 using a comprehensive set of 15 diverse benchmarks (corresponding to approximately 100 tasks and over 36,000 unique prompts). Orca 2 significantly surpasses models of similar size and attains performance levels similar or better to those of models 5-10x larger, as assessed on complex tasks that test advanced reasoning abilities in zero-shot settings. make Orca 2 weights publicly available at aka.ms/orca-lm to support research on the development, evaluation, and alignment of smaller LMs},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\4ZPN6IZX\\Mitra et al. - 2023 - Orca 2 Teaching Small Language Models How to Reas.pdf;C\:\\Users\\oskar\\Zotero\\storage\\LK9TDD3H\\2311.html}
}

@book{mooneyUnderstandingGeospatialSkills2023,
  title = {Towards {{Understanding}} the {{Geospatial Skills}} of {{ChatGPT}}: {{Taking}} a {{Geographic Information Systems}} ({{GIS}}) {{Exam}}},
  shorttitle = {Towards {{Understanding}} the {{Geospatial Skills}} of {{ChatGPT}}},
  author = {Mooney, Peter and Cui, Wencong and Guan, Boyuan and Juh{\'a}sz, Levente},
  year = {2023},
  month = nov,
  doi = {10.1145/3615886.3627745},
  abstract = {This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and ability to grasp geospatial concepts by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3\% (GPT-3.5) and 88.3\% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.},
  file = {C:\Users\oskar\Zotero\storage\2N5LZDKP\Mooney et al. - 2023 - Towards Understanding the Geospatial Skills of Cha.pdf}
}

@article{moorNatureImportanceDifficulty2006,
  title = {The {{Nature}}, {{Importance}}, and {{Difficulty}} of {{Machine Ethics}}},
  author = {Moor, J.H.},
  year = {2006},
  month = jul,
  journal = {IEEE Intelligent Systems},
  volume = {21},
  number = {4},
  pages = {18--21},
  issn = {1941-1294},
  doi = {10.1109/MIS.2006.80},
  url = {https://ieeexplore.ieee.org/document/1667948},
  urldate = {2023-10-05},
  abstract = {Machine ethics has a broad range of possible implementations in computer technology{\textendash}from maintaining detailed records in hospital databases to overseeing emergency team movements after a disaster. From a machine ethics perspective, you can look at machines as ethical-impact agents, implicit ethical agents, explicit ethical agents, or full ethical agents. A current research challenge is to develop machines that are explicit ethical agents. This research is important, but accomplishing this goal will be extremely difficult without a better understanding of ethics and of machine learning and cognition. This article is part of a special issue on Machine Ethics.},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\P4ZBQVD7\\Moor - 2006 - The Nature, Importance, and Difficulty of Machine .pdf;C\:\\Users\\oskar\\Zotero\\storage\\B8H3FN5S\\1667948.html}
}

@article{nascimentoFamilyNaturalLanguage2023,
  title = {A {{Family}} of {{Natural Language Interfaces}} for {{Databases}} Based on {{ChatGPT}} and {{LangChain}}},
  author = {Nascimento, Eduardo and Garc{\'i}a, Grettel and Victorio, Wendy and Lemos, Melissa and Izquierdo, Yenier and Garcia, Robinson and Leme, Luiz and Casanova, Marco},
  year = {2023},
  abstract = {This poster paper proposes a family of Natural Language (NL) interfaces for databases (NLIDBs) that use ChatGPT and LangChain features to compile NL sentences expressing database questions into SQL queries or to extract keywords from NL sentences, which are passed to a database keyword search tool. The use of ChatGPT reduces dealing with NL questions to a few-shot learning process for the benefit of developers interested in creating NLIDBs. The paper concludes by comparing the NLIDBs in the family.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\J7R85NP7\Nascimento et al. - A Family of Natural Language Interfaces for Databa.pdf}
}

@article{neelakandanAutomatedWordEmbedding2021,
  title = {An {{Automated Word Embedding}} with {{Parameter Tuned Model}} for {{Web Crawling}}},
  author = {Neelakandan, S. and Arun, A. and Bhukya, Raghu and Hardas, Bhalchandra and Ch, T. and Ashok, M.},
  year = {2021},
  journal = {Intelligent Automation \& Soft Computing},
  volume = {32},
  number = {3},
  pages = {1617--1632},
  publisher = {{Tech Science Press}},
  issn = {1079-8587, 2326-005X},
  doi = {10.32604/iasc.2022.022209},
  url = {https://www.techscience.com/iasc/v32n3/45909},
  urldate = {2023-10-09},
  abstract = {In recent years, web crawling has gained a significant attention due to the drastic advancements in the World Wide Web. Web Search Engines have the issue of retrieving massive quantity of web documents. One among the web crawlers is the focused crawler, that intends to selectively gather web pages from the Internet. But the efficiency of the focused crawling can easily be affected by the environment of web pages. In this view, this paper presents an Automated Word Embedding with Parameter Tuned Deep Learning (AWE-PTDL) model for focused web crawling. The proposed model involves different processes namely pre-processing, Incremental Skip-gram Model with Negative Sampling (ISGNS) based word embedding, bidirectional long short-term memory-based classification and bird swarm optimization based hyperparameter tuning. The SGNS training desires to go over the complete training data to pre-compute the noise distribution before performing Stochastic Gradient Descent (SGD) and the ISGNS technique is derived for the word embedding process. Besides, the cosine similarity is computed from the word embedding matrix to generate a feature vector which is fed as input into the Bidirectional Long Short-Term Memory (BiLSTM) for the prediction of website relevance. Finally, the Birds Swarm Optimization-Bidirectional Long Short-Term Memory (BSO-BiLSTM) based classification model is used to classify the webpages and the BSO algorithm is employed to determine the hyperparameters of the BiLSTM model so that the overall crawling performance can be considerably enhanced. For validating the enhanced outcome of the presented model, a comprehensive set of simulations are carried out and the results are examined in terms of different measures. The Automated Word Embedding with Parameter Tuned Deep Learning (AWE-PTDL) technique has attained a higher harvest rate of 85\% when compared with the other techniques. The experimental results highlight the enhanced web crawling performance of the proposed model over the recent state of art web crawlers.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\QZZLKUGP\Neelakandan et al. - 2021 - An Automated Word Embedding with Parameter Tuned M.pdf}
}

@article{noormanNegotiatingAutonomyResponsibility2014,
  title = {Negotiating Autonomy and Responsibility in Military Robots},
  author = {Noorman, Merel and Johnson, Deborah G.},
  year = {2014},
  month = mar,
  journal = {Ethics and Information Technology},
  volume = {16},
  number = {1},
  pages = {51--62},
  publisher = {{Springer Nature B.V.}},
  address = {{Dordrecht, Netherlands}},
  issn = {13881957},
  doi = {10.1007/s10676-013-9335-0},
  url = {https://www.proquest.com/docview/1507644287/abstract/4C292C5E3E024E9DPQ/1},
  urldate = {2023-10-05},
  abstract = {Central to the ethical concerns raised by the prospect of increasingly autonomous military robots are issues of responsibility. In this paper we examine different conceptions of autonomy within the discourse on these robots to bring into focus what is at stake when it comes to the autonomous nature of military robots. We argue that due to the metaphorical use of the concept of autonomy, the autonomy of robots is often treated as a black box in discussions about autonomous military robots. When the black box is opened up and we see how autonomy is understood and 'made' by those involved in the design and development of robots, the responsibility questions change significantly.[PUBLICATION ABSTRACT]},
  copyright = {Springer Science+Business Media Dordrecht 2014},
  langid = {english},
  keywords = {Aircraft,Armed forces,Design,Ethics,Library And Information Sciences,Morality,Negotiations,Philosophy,Robots,Studies,Technology},
  file = {C:\Users\oskar\Zotero\storage\GYVB8HB6\Noorman and Johnson - 2014 - Negotiating autonomy and responsibility in militar.pdf}
}

@techreport{norgedigitaltGenerelleVilkarNorge2023,
  title = {Generelle Vilk{\aa}r for {{Norge Digitalt-samarbeidet}}},
  author = {{Norge Digitalt}},
  year = {2023},
  url = {https://www.geonorge.no/globalassets/geonorge2/avtaler-og-bilag-norge-digitalt/generelle-vilkar.pdf},
  urldate = {2023-10-23},
  file = {C:\Users\oskar\Zotero\storage\VPT7EGAL\generelle-vilkar.pdf}
}

@misc{ogcOGCStandards2023,
  title = {{{OGC Standards}}},
  author = {{OGC}},
  year = {2023},
  month = oct,
  journal = {Open Geospatial Consortium},
  url = {https://www.ogc.org/standards/},
  urldate = {2023-10-23},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\QWK5I79E\\ogc.png;C\:\\Users\\oskar\\Zotero\\storage\\37QGTLZ7\\standards.html}
}

@misc{openaiGPT4TechnicalReport2023,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI},
  year = {2023},
  month = mar,
  number = {arXiv:2303.08774},
  eprint = {2303.08774},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2303.08774},
  url = {http://arxiv.org/abs/2303.08774},
  urldate = {2023-10-09},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\U4ISGUBN\\OpenAI - 2023 - GPT-4 Technical Report.pdf;C\:\\Users\\oskar\\Zotero\\storage\\ANYBWPS8\\2303.html}
}

@misc{openaiIntroducingChatGPT2022,
  title = {Introducing {{ChatGPT}}},
  author = {{OpenAI}},
  year = {2022},
  month = nov,
  url = {https://openai.com/blog/chatgpt},
  urldate = {2023-10-26},
  abstract = {We've trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\BXCIMZNC\chatgpt.html}
}

@article{oscoPotentialVisualChatGPT2023,
  title = {The {{Potential}} of {{Visual ChatGPT}} for {{Remote Sensing}}},
  author = {Osco, Lucas Prado and de Lemos, Eduardo Lopes and Gon{\c c}alves, Wesley Nunes and Ramos, Ana Paula Marques and Marcato Junior, Jos{\'e}},
  year = {2023},
  month = jan,
  journal = {Remote Sensing},
  volume = {15},
  number = {13},
  pages = {3232},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2072-4292},
  doi = {10.3390/rs15133232},
  url = {https://www.mdpi.com/2072-4292/15/13/3232},
  urldate = {2023-10-30},
  abstract = {Recent advancements in Natural Language Processing (NLP), particularly in Large Language Models (LLMs), associated with deep learning-based computer vision techniques, have shown substantial potential for automating a variety of tasks. These are known as Visual LLMs and one notable model is Visual ChatGPT, which combines ChatGPT's LLM capabilities with visual computation to enable effective image analysis. These models' abilities to process images based on textual inputs can revolutionize diverse fields, and while their application in the remote sensing domain remains unexplored, it is important to acknowledge that novel implementations are to be expected. Thus, this is the first paper to examine the potential of Visual ChatGPT, a cutting-edge LLM founded on the GPT architecture, to tackle the aspects of image processing related to the remote sensing domain. Among its current capabilities, Visual ChatGPT can generate textual descriptions of images, perform canny edge and straight line detection, and conduct image segmentation. These offer valuable insights into image content and facilitate the interpretation and extraction of information. By exploring the applicability of these techniques within publicly available datasets of satellite images, we demonstrate the current model's limitations in dealing with remote sensing images, highlighting its challenges and future prospects. Although still in early development, we believe that the combination of LLMs and visual models holds a significant potential to transform remote sensing image processing, creating accessible and practical application opportunities in the field.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {artificial intelligence,image analysis,visual language model},
  file = {C:\Users\oskar\Zotero\storage\TB43HJRE\Osco et al. - 2023 - The Potential of Visual ChatGPT for Remote Sensing.pdf}
}

@misc{ouyangTrainingLanguageModels2022,
  title = {Training Language Models to Follow Instructions with Human Feedback},
  author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
  year = {2022},
  month = mar,
  number = {arXiv:2203.02155},
  eprint = {2203.02155},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2203.02155},
  url = {http://arxiv.org/abs/2203.02155},
  urldate = {2023-10-09},
  abstract = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\2GXBWJNW\\Ouyang et al. - 2022 - Training language models to follow instructions wi.pdf;C\:\\Users\\oskar\\Zotero\\storage\\587BTE6P\\2203.html}
}

@inproceedings{papineniBleuMethodAutomatic2002,
  title = {Bleu: A {{Method}} for {{Automatic Evaluation}} of {{Machine Translation}}},
  shorttitle = {Bleu},
  booktitle = {Proceedings of the 40th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  editor = {Isabelle, Pierre and Charniak, Eugene and Lin, Dekang},
  year = {2002},
  month = jul,
  pages = {311--318},
  publisher = {{Association for Computational Linguistics}},
  address = {{Philadelphia, Pennsylvania, USA}},
  doi = {10.3115/1073083.1073135},
  url = {https://aclanthology.org/P02-1040},
  urldate = {2023-12-07},
  file = {C:\Users\oskar\Zotero\storage\B5PXQHSU\Papineni et al. - 2002 - Bleu a Method for Automatic Evaluation of Machine.pdf}
}

@misc{PauseGiantAI,
  title = {Pause {{Giant AI Experiments}}: {{An Open Letter}}},
  shorttitle = {Pause {{Giant AI Experiments}}},
  journal = {Future of Life Institute},
  url = {https://futureoflife.org/open-letter/pause-giant-ai-experiments/},
  urldate = {2023-10-06},
  abstract = {We call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4.},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\M7E3WLIG\pause-giant-ai-experiments.html}
}

@misc{pengInstructionTuningGPT42023,
  title = {Instruction {{Tuning}} with {{GPT-4}}},
  author = {Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  year = {2023},
  month = apr,
  number = {arXiv:2304.03277},
  eprint = {2304.03277},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2304.03277},
  url = {http://arxiv.org/abs/2304.03277},
  urldate = {2023-10-09},
  abstract = {Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed. In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning. Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models. We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training. We make our data generated using GPT-4 as well as our codebase publicly available.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\7Z453WF5\\Peng et al. - 2023 - Instruction Tuning with GPT-4.pdf;C\:\\Users\\oskar\\Zotero\\storage\\NXD74743\\2304.html}
}

@misc{pichaiIntroducingGeminiOur2023,
  title = {Introducing {{Gemini}}: Our Largest and Most Capable {{AI}} Model},
  shorttitle = {Introducing {{Gemini}}},
  author = {Pichai, Sundar and Hassabis, Demis},
  year = {2023},
  month = dec,
  journal = {Google},
  url = {https://blog.google/technology/ai/google-gemini-ai/},
  urldate = {2023-12-07},
  abstract = {Gemini is our most capable and general model, built to be multimodal and optimized for three different sizes: Ultra, Pro and Nano.},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\9KY4QCRJ\google-gemini-ai.html}
}

@misc{qiMaaSDBSpatialDatabases2023,
  title = {{{MaaSDB}}: {{Spatial Databases}} in the {{Era}} of {{Large Language Models}} ({{Vision Paper}})},
  shorttitle = {{{MaaSDB}}},
  author = {Qi, Jianzhong and Li, Zuqing and Tanin, Egemen},
  year = {2023},
  month = sep,
  eprint = {2309.17072},
  primaryclass = {cs},
  doi = {10.1145/3589132.3625597},
  url = {http://arxiv.org/abs/2309.17072},
  urldate = {2023-10-06},
  abstract = {Large language models (LLMs) are advancing rapidly. Such models have demonstrated strong capabilities in learning from large-scale (unstructured) text data and answering user queries. Users do not need to be experts in structured query languages to interact with systems built upon such models. This provides great opportunities to reduce the barrier of information retrieval for the general public. By introducing LLMs into spatial data management, we envisage an LLM-based spatial database system to learn from both structured and unstructured spatial data. Such a system will offer seamless access to spatial knowledge for the users, thus benefiting individuals, business, and government policy makers alike.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Databases},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\YZDM594F\\Qi et al. - 2023 - MaaSDB Spatial Databases in the Era of Large Lang.pdf;C\:\\Users\\oskar\\Zotero\\storage\\V87YV6DH\\2309.html}
}

@misc{rabbitholesyndromeEmbeddingsOpenAIVs2023,
  title = {\$0 {{Embeddings}} ({{OpenAI}} vs. Free \& Open Source)},
  author = {{Rabbit Hole Syndrome}},
  year = {2023},
  month = jun,
  url = {https://www.youtube.com/watch?v=QdDoFfkVkcw},
  urldate = {2023-10-08},
  abstract = {What is the cheapest way to generate text embeddings? And how do they compare to OpenAI? To try everything Brilliant has to offer{\textemdash}free{\textemdash}for a full 30 days, visit https://brilliant.org/RabbitHoleSyndrome. The first 200 of you will get 20\% off Brilliant's annual premium subscription. This video was sponsored by Brilliant. The video is going to explore the world of open source embedding models, how to use them, and how they compare to OpenAI's text-embedding-ada-002. Source code: https://github.com/rabbit-hole-syndro... Sentence Embeddings (SBERT): https://sbert.net/ MTEB Leaderboard: https://huggingface.co/spaces/mteb/le... 00:00 Intro 02:02 Project setup 03:29 Embeddings 101 05:07 Server-side Embeddings 06:14 SBERT \& Hugging Face 10:22 Sentence Transformers Models 17:18 MTEB 28:35 Inference API 55:37 Transformers.js 1:10:38 Embeddings in the Browser 1:20:19 The Future of Embeddings 1:24:23 Thanks for watching!}
}

@misc{rabieiColloquialPersianPOS2023,
  title = {Colloquial {{Persian POS}} ({{CPPOS}}) {{Corpus}}: {{A Novel Corpus}} for {{Colloquial Persian Part}} of {{Speech Tagging}}},
  shorttitle = {Colloquial {{Persian POS}} ({{CPPOS}}) {{Corpus}}},
  author = {Rabiei, Leyla and Rahmani, Farzaneh and Khansari, Mohammad and Rajabi, Zeinab and Salimi, Moein},
  year = {2023},
  month = oct,
  number = {arXiv:2310.00572},
  eprint = {2310.00572},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2310.00572},
  url = {http://arxiv.org/abs/2310.00572},
  urldate = {2023-10-06},
  abstract = {Introduction: Part-of-Speech (POS) Tagging, the process of classifying words into their respective parts of speech (e.g., verb or noun), is essential in various natural language processing applications. POS tagging is a crucial preprocessing task for applications like machine translation, question answering, sentiment analysis, etc. However, existing corpora for POS tagging in Persian mainly consist of formal texts, such as daily news and newspapers. As a result, smart POS tools, machine learning models, and deep learning models trained on these corpora may not perform optimally for processing colloquial text in social network analysis. Method: This paper introduces a novel corpus, "Colloquial Persian POS" (CPPOS), specifically designed to support colloquial Persian text. The corpus includes formal and informal text collected from various domains such as political, social, and commercial on Telegram, Twitter, and Instagram more than 520K labeled tokens. After collecting posts from these social platforms for one year, special preprocessing steps were conducted, including normalization, sentence tokenizing, and word tokenizing for social text. The tokens and sentences were then manually annotated and verified by a team of linguistic experts. This study also defines a POS tagging guideline for annotating the data and conducting the annotation process. Results: To evaluate the quality of CPPOS, various deep learning models, such as the RNN family, were trained using the constructed corpus. A comparison with another well-known Persian POS corpus named "Bijankhan" and the Persian Hazm POS tool trained on Bijankhan revealed that our model trained on CPPOS outperforms them. With the new corpus and the BiLSTM deep neural model, we achieved a 14\% improvement over the previous dataset.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\UIG9F6SJ\\Rabiei et al. - 2023 - Colloquial Persian POS (CPPOS) Corpus A Novel Cor.pdf;C\:\\Users\\oskar\\Zotero\\storage\\8KS2LXMR\\2310.html}
}

@inproceedings{radfordImprovingLanguageUnderstanding2018,
  title = {Improving {{Language Understanding}} by {{Generative Pre-Training}}},
  author = {Radford, Alec and Narasimhan, Karthik},
  year = {2018},
  url = {https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035},
  urldate = {2023-10-09},
  abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
  file = {C:\Users\oskar\Zotero\storage\HR6GDGYQ\Radford and Narasimhan - 2018 - Improving Language Understanding by Generative Pre.pdf}
}

@article{raffelExploringLimitsTransfer2020,
  title = {Exploring the {{Limits}} of {{Transfer Learning}} with a {{Unified Text-to-Text Transformer}}},
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  year = {2020},
  journal = {JOURNAL OF MACHINE LEARNING RESEARCH},
  volume = {21},
  pages = {140},
  publisher = {{Microtome Publ}},
  address = {{Brookline}},
  issn = {1532-4435},
  url = {https://www.webofscience.com/wos/woscc/full-record/WOS:000558791600001},
  urldate = {2023-10-09},
  abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.(1)},
  langid = {english},
  keywords = {attention-based models,deep learning,multi-task learning,natural language processing,transfer learning},
  annotation = {Web of Science ID: WOS:000558791600001},
  file = {C:\Users\oskar\Zotero\storage\9BGGZZWU\Raffel et al. - 2020 - Exploring the Limits of Transfer Learning with a U.pdf}
}

@misc{ResourceSiteISO,
  title = {Resource Site for {{ISO}}/{{TC}} 211 {{Geographic}} Information/{{Geomatics}} {\textemdash} {{Resource}} Site for {{ISO}}/{{TC}} 211 {{Geographic}} Information/{{Geomatics}}},
  url = {https://www.isotc211.org/},
  urldate = {2023-10-23},
  file = {C:\Users\oskar\Zotero\storage\48F3RTE9\www.isotc211.org.html}
}

@article{rezaeiniaSentimentAnalysisBased2019,
  title = {Sentiment Analysis Based on Improved Pre-Trained Word Embeddings},
  author = {Rezaeinia, Seyed Mahdi and Rahmani, Rouhollah and Ghodsi, Ali and Veisi, Hadi},
  year = {2019},
  month = mar,
  journal = {Expert Systems with Applications},
  volume = {117},
  pages = {139--147},
  issn = {09574174},
  doi = {10.1016/j.eswa.2018.08.044},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S095741741830558X},
  urldate = {2023-10-09},
  langid = {english},
  keywords = {Deep learning,GloVe,Natural language processing,Sentiment analysis,Word embeddings,Word2Vec},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\8R4XPURF\\Rezaeinia et al. - 2019 - Sentiment analysis based on improved pre-trained w.pdf;C\:\\Users\\oskar\\Zotero\\storage\\DU4XSKTQ\\S095741741830558X.html}
}

@misc{richardAutoGPTHeartOpensource2023,
  title = {{{AutoGPT}}: The Heart of the Open-Source Agent Ecosystem},
  shorttitle = {{{AutoGPT}}},
  author = {Richard, Toran Bruce},
  year = {2023},
  month = oct,
  url = {https://github.com/Significant-Gravitas/AutoGPT},
  urldate = {2023-10-05},
  abstract = {An experimental open-source attempt to make GPT-4 fully autonomous.},
  copyright = {MIT},
  howpublished = {AutoGPT},
  keywords = {ai,artificial-intelligence,autonomous-agents,gpt-4,openai,python}
}

@misc{robertsGPT4GEOHowLanguage2023,
  title = {{{GPT4GEO}}: {{How}} a {{Language Model Sees}} the {{World}}'s {{Geography}}},
  shorttitle = {{{GPT4GEO}}},
  author = {Roberts, Jonathan and L{\"u}ddecke, Timo and Das, Sowmen and Han, Kai and Albanie, Samuel},
  year = {2023},
  month = may,
  number = {arXiv:2306.00020},
  eprint = {2306.00020},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2306.00020},
  url = {http://arxiv.org/abs/2306.00020},
  urldate = {2023-10-05},
  abstract = {Large language models (LLMs) have shown remarkable capabilities across a broad range of tasks involving question answering and the generation of coherent text and code. Comprehensively understanding the strengths and weaknesses of LLMs is beneficial for safety, downstream applications and improving performance. In this work, we investigate the degree to which GPT-4 has acquired factual geographic knowledge and is capable of using this knowledge for interpretative reasoning, which is especially important for applications that involve geographic data, such as geospatial analysis, supply chain management, and disaster response. To this end, we design and conduct a series of diverse experiments, starting from factual tasks such as location, distance and elevation estimation to more complex questions such as generating country outlines and travel networks, route finding under constraints and supply chain analysis. We provide a broad characterisation of what GPT-4 (without plugins or Internet access) knows about the world, highlighting both potentially surprising capabilities but also limitations.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\7DRKDHXI\\Roberts et al. - 2023 - GPT4GEO How a Language Model Sees the World's Geo.pdf;C\:\\Users\\oskar\\Zotero\\storage\\BHCR5VUS\\2306.html}
}

@misc{roziereCodeLlamaOpen2023,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  shorttitle = {Code {{Llama}}},
  author = {Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and Kozhevnikov, Artyom and Evtimov, Ivan and Bitton, Joanna and Bhatt, Manish and Ferrer, Cristian Canton and Grattafiori, Aaron and Xiong, Wenhan and D{\'e}fossez, Alexandre and Copet, Jade and Azhar, Faisal and Touvron, Hugo and Martin, Louis and Usunier, Nicolas and Scialom, Thomas and Synnaeve, Gabriel},
  year = {2023},
  month = aug,
  number = {arXiv:2308.12950},
  eprint = {2308.12950},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2308.12950},
  urldate = {2023-10-30},
  abstract = {We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53\% and 55\% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\HG5BUPY7\\Rozière et al. - 2023 - Code Llama Open Foundation Models for Code.pdf;C\:\\Users\\oskar\\Zotero\\storage\\XF7M2VMP\\2308.html}
}

@misc{roziereCodeLlamaOpen2023a,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  shorttitle = {Code {{Llama}}},
  author = {Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and Kozhevnikov, Artyom and Evtimov, Ivan and Bitton, Joanna and Bhatt, Manish and Ferrer, Cristian Canton and Grattafiori, Aaron and Xiong, Wenhan and D{\'e}fossez, Alexandre and Copet, Jade and Azhar, Faisal and Touvron, Hugo and Martin, Louis and Usunier, Nicolas and Scialom, Thomas and Synnaeve, Gabriel},
  year = {2023},
  month = aug,
  number = {arXiv:2308.12950},
  eprint = {2308.12950},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2308.12950},
  urldate = {2023-12-06},
  abstract = {We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53\% and 55\% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\ZMFJYZFI\\Rozière et al. - 2023 - Code Llama Open Foundation Models for Code.pdf;C\:\\Users\\oskar\\Zotero\\storage\\24UFYPRZ\\2308.html}
}

@inproceedings{scherrerHeLjuVarDial20202020,
  title = {{{HeLju}}@{{VarDial}} 2020: {{Social Media Variety Geolocation}} with {{BERT Models}}},
  shorttitle = {{{HeLju}}@{{VarDial}} 2020},
  booktitle = {Proceedings of the 7th {{Workshop}} on {{NLP}} for {{Similar Languages}}, {{Varieties}} and {{Dialects}}},
  author = {Scherrer, Yves and Ljube{\v s}i{\'c}, Nikola},
  year = {2020},
  month = dec,
  pages = {202--211},
  publisher = {{International Committee on Computational Linguistics (ICCL)}},
  address = {{Barcelona, Spain (Online)}},
  url = {https://aclanthology.org/2020.vardial-1.19},
  urldate = {2023-10-16},
  abstract = {This paper describes the Helsinki-Ljubljana contribution to the VarDial shared task on social media variety geolocation. Our solutions are based on the BERT Transformer models, the constrained versions of our models reaching 1st place in two subtasks and 3rd place in one subtask, while our unconstrained models outperform all the constrained systems by a large margin. We show in our analyses that Transformer-based models outperform traditional models by far, and that improvements obtained by pre-training models on large quantities of (mostly standard) text are significant, but not drastic, with single-language models also outperforming multilingual models. Our manual analysis shows that two types of signals are the most crucial for a (mis)prediction: named entities and dialectal features, both of which are handled well by our models.},
  file = {C:\Users\oskar\Zotero\storage\SXY6K8F7\Scherrer and Ljubešić - 2020 - HeLju@VarDial 2020 Social Media Variety Geolocati.pdf}
}

@article{sheppardGISSocietyResearch1995,
  title = {{{GIS}} and {{Society}}: {{Towards}} a {{Research Agenda}}},
  shorttitle = {{{GIS}} and {{Society}}},
  author = {Sheppard, Eric},
  year = {1995},
  month = jan,
  journal = {Cartography and Geographic Information Systems},
  volume = {22},
  number = {1},
  pages = {5--16},
  publisher = {{Taylor \& Francis}},
  issn = {1050-9844},
  doi = {10.1559/152304095782540555},
  url = {https://doi.org/10.1559/152304095782540555},
  urldate = {2023-12-02},
  abstract = {Recognition that GIS is a social technology implies that the GIS research agenda should be broadened to incorporate questions of the social imbeddedness and impact of GIS. Research into these questions can draw on the complementary skills of GIS specialists and social theorists. GIS as we know it is not the only form it could have taken, but has followed a direction of development shaped by technical and social conditions. GIS represents the world in certain ways that privilege instrumental logic over other ways of knowing. GIS can have significant consequences affecting the outcome of social problems which it is employed to solve, depending on differential access to GIS and information, and on what is defined as information. Such issues suggest a rich agenda for future research.},
  keywords = {EPISTEMOLOGICAL DIVERSITY,GIS,HISTORY OF GIS,RESEARCH AGENDA,SOCIAL THEORY,TECHNOLOGY AND SOCIETY}
}

@misc{shevlaneModelEvaluationExtreme2023,
  title = {Model Evaluation for Extreme Risks},
  author = {Shevlane, Toby and Farquhar, Sebastian and Garfinkel, Ben and Phuong, Mary and Whittlestone, Jess and Leung, Jade and Kokotajlo, Daniel and Marchal, Nahema and Anderljung, Markus and Kolt, Noam and Ho, Lewis and Siddarth, Divya and Avin, Shahar and Hawkins, Will and Kim, Been and Gabriel, Iason and Bolina, Vijay and Clark, Jack and Bengio, Yoshua and Christiano, Paul and Dafoe, Allan},
  year = {2023},
  month = may,
  journal = {arXiv.org},
  url = {https://arxiv.org/abs/2305.15324v2},
  urldate = {2023-10-09},
  abstract = {Current approaches to building general-purpose AI systems tend to produce systems with both beneficial and harmful capabilities. Further progress in AI development could lead to capabilities that pose extreme risks, such as offensive cyber capabilities or strong manipulation skills. We explain why model evaluation is critical for addressing extreme risks. Developers must be able to identify dangerous capabilities (through "dangerous capability evaluations") and the propensity of models to apply their capabilities for harm (through "alignment evaluations"). These evaluations will become critical for keeping policymakers and other stakeholders informed, and for making responsible decisions about model training, deployment, and security.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\29PNLI8M\Shevlane et al. - 2023 - Model evaluation for extreme risks.pdf}
}

@misc{shiREPLUGRetrievalAugmentedBlackBox2023,
  title = {{{REPLUG}}: {{Retrieval-Augmented Black-Box Language Models}}},
  shorttitle = {{{REPLUG}}},
  author = {Shi, Weijia and Min, Sewon and Yasunaga, Michihiro and Seo, Minjoon and James, Rich and Lewis, Mike and Zettlemoyer, Luke and Yih, Wen-tau},
  year = {2023},
  month = may,
  number = {arXiv:2301.12652},
  eprint = {2301.12652},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2301.12652},
  url = {http://arxiv.org/abs/2301.12652},
  urldate = {2023-12-12},
  abstract = {We introduce REPLUG, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model. Unlike prior retrieval-augmented LMs that train language models with special cross attention mechanisms to encode the retrieved text, REPLUG simply prepends retrieved documents to the input for the frozen black-box LM. This simple design can be easily applied to any existing retrieval and language models. Furthermore, we show that the LM can be used to supervise the retrieval model, which can then find documents that help the LM make better predictions. Our experiments demonstrate that REPLUG with the tuned retriever significantly improves the performance of GPT-3 (175B) on language modeling by 6.3\%, as well as the performance of Codex on five-shot MMLU by 5.1\%.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\C4MRW2R6\\Shi et al. - 2023 - REPLUG Retrieval-Augmented Black-Box Language Mod.pdf;C\:\\Users\\oskar\\Zotero\\storage\\MZUGXWFF\\2301.html}
}

@misc{skjuveWhyPeopleUse2023,
  type = {{{SSRN Scholarly Paper}}},
  title = {Why {{People Use ChatGPT}}},
  author = {Skjuve, Marita and Bae Brandtzaeg, Petter and F{\o}lstad, Asbj{\o}rn},
  year = {2023},
  month = mar,
  number = {4376834},
  address = {{Rochester, NY}},
  doi = {10.2139/ssrn.4376834},
  url = {https://papers.ssrn.com/abstract=4376834},
  urldate = {2023-10-25},
  abstract = {ChatGPT, a general-purpose conversational artificial intelligence (AI), has attracted substantial attention since its launch in November 2022. The advent of this technology showcases AI's vast potential for generating and processing text and raises compelling questions regarding its potential usages. To obtain the requisite knowledge of users' motivations in adopting ChatGPT, we conducted a survey among ChatGPT users (N = 197) and analyzed the findings within the uses and gratifications (U\&G) theoretical framework. We identified six primary motivations for using ChatGPT: productivity, novelty, creative work, learning and development, entertainment, and social interaction and support. Our findings demonstrate that a general-purpose conversational AI such as ChatGPT have the potential to impact multiple aspects of human life, from enhancing work efficiency to shaping communication between individuals. We consider the possible consequences of such diverse user motivations and highlight potential avenues for further research.},
  langid = {english},
  keywords = {ChatGPT,Conversational AI,Large Language Models,Motivations,Uses and Gratifications},
  file = {C:\Users\oskar\Zotero\storage\6CBMX6DH\Skjuve et al. - 2023 - Why People Use ChatGPT.pdf}
}

@article{sparrowKillerRobots2007,
  title = {Killer {{Robots}}},
  author = {Sparrow, Robert},
  year = {2007},
  month = feb,
  journal = {Journal of Applied Philosophy},
  volume = {24},
  number = {1},
  pages = {62--77},
  publisher = {{Wiley-Blackwell}},
  issn = {02643758},
  doi = {10.1111/j.1468-5930.2007.00346.x},
  url = {https://search.ebscohost.com/login.aspx?direct=true&db=a9h&AN=23774147&site=ehost-live},
  urldate = {2023-10-05},
  abstract = {The United States Army's Future Combat Systems Project, which aims to manufacture a `robot army' to be ready for deployment by 2012, is only the latest and most dramatic example of military interest in the use of artificially intelligent systems in modern warfare. This paper considers the ethics of the decision to send artificially intelligent robots into war, by asking who we should hold responsible when an autonomous weapon system is involved in an atrocity of the sort that would normally be described as a war crime. A number of possible loci of responsibility for robot war crimes are canvassed: the persons who designed or programmed the system, the commanding officer who ordered its use, the machine itself. I argue that in fact none of these are ultimately satisfactory. Yet it is a necessary condition for fighting a just war, under the principle of jus in bellum, that someone can be justly held responsible for deaths that occur in the course of the war. As this condition cannot be met in relation to deaths caused by an autonomous weapon system it would therefore be unethical to deploy such systems in warfare.},
  keywords = {ARTIFICIAL intelligence,ETHICS,MILITARY science,ROBOTS,UNITED States. Army},
  file = {C:\Users\oskar\Zotero\storage\AN6UJNPA\Sparrow - 2007 - Killer Robots.pdf}
}

@misc{STACTutorials,
  title = {{{STAC Tutorials}}},
  url = {https://stacspec.org/en/tutorials/},
  urldate = {2023-10-23},
  abstract = {Here you can find our library of tutorials for learning all about STAC.},
  langid = {english}
}

@inproceedings{stasaskiSemanticDiversityDialogue2022,
  title = {Semantic {{Diversity}} in {{Dialogue}} with {{Natural Language Inference}}},
  booktitle = {Proceedings of the 2022 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Stasaski, Katherine and Hearst, Marti},
  editor = {Carpuat, Marine and {de Marneffe}, Marie-Catherine and Meza Ruiz, Ivan Vladimir},
  year = {2022},
  month = jul,
  pages = {85--98},
  publisher = {{Association for Computational Linguistics}},
  address = {{Seattle, United States}},
  doi = {10.18653/v1/2022.naacl-main.6},
  url = {https://aclanthology.org/2022.naacl-main.6},
  urldate = {2023-12-09},
  abstract = {Generating diverse, interesting responses to chitchat conversations is a problem for neural conversational agents. This paper makes two substantial contributions to improving diversity in dialogue generation. First, we propose a novel metric which uses Natural Language Inference (NLI) to measure the semantic diversity of a set of model responses for a conversation. We evaluate this metric using an established framework (Tevet and Berant, 2021) and find strong evidence indicating NLI Diversity is correlated with semantic diversity. Specifically, we show that the contradiction relation is more useful than the neutral relation for measuring this diversity and that incorporating the NLI model's confidence achieves state-of-the-art results. Second, we demonstrate how to iteratively improve the semantic diversity of a sampled set of responses via a new generation procedure called Diversity Threshold Generation, which results in an average 137\% increase in NLI Diversity compared to standard generation procedures.},
  file = {C:\Users\oskar\Zotero\storage\R2WFFNVN\Stasaski and Hearst - 2022 - Semantic Diversity in Dialogue with Natural Langua.pdf}
}

@misc{StrengtheningEuropeanAI,
  title = {Strengthening the {{European AI Act}}},
  journal = {Future of Life Institute},
  url = {https://futureoflife.org/project/eu-ai-act/},
  urldate = {2023-10-06},
  abstract = {The FLI EU Policy Team works on strengthening the European Union Artificial Intelligence (AI) Act draft law. Read our position and research papers.},
  langid = {american},
  file = {C:\Users\oskar\Zotero\storage\YYZZHLLS\eu-ai-act.html}
}

@misc{sunExploringImpactLowrank2023,
  title = {Exploring the Impact of Low-Rank Adaptation on the Performance, Efficiency, and Regularization of {{RLHF}}},
  author = {Sun, Simeng and Gupta, Dhawal and Iyyer, Mohit},
  year = {2023},
  month = sep,
  number = {arXiv:2309.09055},
  eprint = {2309.09055},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2309.09055},
  url = {http://arxiv.org/abs/2309.09055},
  urldate = {2023-10-09},
  abstract = {During the last stage of RLHF, a large language model is aligned to human intents via PPO training, a process that generally requires large-scale computational resources. In this technical report, we empirically investigate an efficient implementation of RLHF using low-rank adaptation (LoRA), which allows us to align the LLaMA 7B checkpoint on the Alpaca dataset using only two A100 GPUs instead of the eight required for full model fine-tuning. Despite tuning only 0.2\% of LLaMA 7B's parameters, our implementation achieves better performance than the publicly-released AlpacaFarm checkpoint with full model fine-tuning. Next, we analyze several configurations of our LoRA-based PPO implementation, varying the form of the KL regularization term in the training objective. We find that (1) removing this penalty term does not harm performance on the AlpacaFarm evaluation set under our LoRA setup; (2) other regularizers, such as Jensen-Shannon divergence, lead to improved performance; and (3) while PPO training negatively impacts the factuality of model-generated responses, training with LoRA largely mitigates this effect. We release our code and pretrained checkpoints to facilitate future research on more efficient RLHF.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\VRDRSGTA\\Sun et al. - 2023 - Exploring the impact of low-rank adaptation on the.pdf;C\:\\Users\\oskar\\Zotero\\storage\\TLSXWYT4\\2309.html}
}

@misc{suzgunChallengingBIGBenchTasks2022,
  title = {Challenging {{BIG-Bench Tasks}} and {{Whether Chain-of-Thought Can Solve Them}}},
  author = {Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V. and Chi, Ed H. and Zhou, Denny and Wei, Jason},
  year = {2022},
  month = oct,
  number = {arXiv:2210.09261},
  eprint = {2210.09261},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2210.09261},
  urldate = {2023-12-09},
  abstract = {BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite that focuses on tasks believed to be beyond the capabilities of current language models. Language models have already made good progress on this benchmark, with the best model in the BIG-Bench paper outperforming average reported human-rater results on 65\% of the BIG-Bench tasks via few-shot prompting. But on what tasks do language models fall short of average human-rater performance, and are those tasks actually unsolvable by current language models? In this work, we focus on a suite of 23 challenging BIG-Bench tasks which we call BIG-Bench Hard (BBH). These are the task for which prior language model evaluations did not outperform the average human-rater. We find that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex (code-davinci-002) to surpass the average human-rater performance on 17 of the 23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot prompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al., 2022), substantially underestimates the best performance and capabilities of language models, which is better captured via CoT prompting. As further analysis, we explore the interaction between CoT and model scale on BBH, finding that CoT enables emergent task performance on several BBH tasks with otherwise flat scaling curves.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\LQR9D9UB\\Suzgun et al. - 2022 - Challenging BIG-Bench Tasks and Whether Chain-of-T.pdf;C\:\\Users\\oskar\\Zotero\\storage\\C9V3K24C\\2210.html}
}

@misc{tangScienceDetectingLLMGenerated2023,
  title = {The {{Science}} of {{Detecting LLM-Generated Texts}}},
  author = {Tang, Ruixiang and Chuang, Yu-Neng and Hu, Xia},
  year = {2023},
  month = jun,
  number = {arXiv:2303.07205},
  eprint = {2303.07205},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2303.07205},
  url = {http://arxiv.org/abs/2303.07205},
  urldate = {2023-12-07},
  abstract = {The emergence of large language models (LLMs) has resulted in the production of LLM-generated texts that is highly sophisticated and almost indistinguishable from texts written by humans. However, this has also sparked concerns about the potential misuse of such texts, such as spreading misinformation and causing disruptions in the education system. Although many detection approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. This survey aims to provide an overview of existing LLM-generated text detection techniques and enhance the control and regulation of language generation models. Furthermore, we emphasize crucial considerations for future research, including the development of comprehensive evaluation metrics and the threat posed by open-source LLMs, to drive progress in the area of LLM-generated text detection.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\55K4LBCX\\Tang et al. - 2023 - The Science of Detecting LLM-Generated Texts.pdf;C\:\\Users\\oskar\\Zotero\\storage\\V75SUKWY\\2303.html}
}

@techreport{taoriAlpacaStrongReplicable,
  title = {Alpaca: {{A Strong}}, {{Replicable Instruction-Following Model}}},
  author = {Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatasunori B.},
  institution = {{Stanford Center for Research on Foundational Models}},
  url = {https://crfm.stanford.edu/2023/03/13/alpaca.html},
  urldate = {2023-10-09},
  file = {C:\Users\oskar\Zotero\storage\3WAULKQY\alpaca.html}
}

@misc{TaskdrivenAutonomousAgent2023,
  title = {Task-Driven {{Autonomous Agent Utilizing GPT-4}}, {{Pinecone}}, and {{LangChain}} for {{Diverse Applications}} {\textendash} {{Yohei Nakajima}}},
  year = {2023},
  month = mar,
  url = {https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/},
  urldate = {2023-10-09},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\KB5GNQBP\task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications.html}
}

@techreport{thenorwegianmappingauthorityElveg2019,
  title = {{Elveg 2.0}},
  author = {{The Norwegian Mapping Authority}},
  year = {2019},
  month = dec,
  url = {https://register.geonorge.no/data/documents/Produktspesifikasjoner_elveg-2-0_v2_sosi-standardisert-produktspesifikasjon-elveg-2_0_1_.pdf},
  urldate = {2023-12-02},
  langid = {norsk},
  file = {C:\Users\oskar\Zotero\storage\TUVKD3T5\Produktspesifikasjoner_elveg-2-0_v2_sosi-standardisert-produktspesifikasjon-elveg-2_0_1_.pdf}
}

@techreport{thenorwegianmappingauthorityHandbokGeovekstsamarbeidet2023,
  title = {{H{\aa}ndbok for Geovekst-samarbeidet}},
  author = {{The Norwegian Mapping Authority}},
  year = {2023},
  month = sep,
  institution = {{Kartverket}},
  url = {https://kartverket.no/geodataarbeid/geovekst/veiledningsmateriell-geovekst/},
  urldate = {2023-10-10},
  abstract = {Geovekst er et partssamarbeid om felles etablering, forvaltning, drift, vedlikehold og bruk av detaljerte kartdata og ortofoto. Nasjonale retningslinjer for samarbeidet samordnes igjennom Geovekst-forum. Geovekst-dataene sikres og oppdate {\ldots}},
  langid = {norwegianbokmal},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\WRAWFM5K\\2023 - Håndbok for Geovekst-samarbeidet.pdf;C\:\\Users\\oskar\\Zotero\\storage\\FMVCCWW3\\veiledningsmateriell-geovekst.html}
}

@article{topsakalCreatingLargeLanguage2023,
  title = {Creating {{Large Language Model Applications Utilizing LangChain}}: {{A Primer}} on {{Developing LLM Apps Fast}}},
  shorttitle = {Creating {{Large Language Model Applications Utilizing LangChain}}},
  author = {Topsakal, Oguzhan and Akinci, T. Cetin},
  year = {2023},
  month = jul,
  journal = {International Conference on Applied Engineering and Natural Sciences},
  volume = {1},
  pages = {1050--1056},
  doi = {10.59287/icaens.1127},
  abstract = {This study focuses on the utilization of Large Language Models (LLMs) for the rapid development of applications, with a spotlight on LangChain, an open-source software library. LLMs have been rapidly adopted due to their capabilities in a range of tasks, including essay composition, code writing, explanation, and debugging, with OpenAI's ChatGPT popularizing their usage among millions ofusers. The crux of the study centers around LangChain, designed to expedite the development of bespoke AI applications using LLMs. LangChain has been widely recognized in the AI community for its ability to seamlessly interact with various data sources and applications. The paper provides an examination of LangChain's core features, including its components and chains, acting as modular abstractions and customizable, use-case-specific pipelines, respectively. Through a series of practical examples, the study elucidates the potential of this framework in fostering the swift development of LLM-based applications.},
  file = {C:\Users\oskar\Zotero\storage\586XFC8J\Topsakal and Akinci - 2023 - Creating Large Language Model Applications Utilizi.pdf}
}

@misc{touvronLLaMAOpenEfficient2023,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  year = {2023},
  month = feb,
  number = {arXiv:2302.13971},
  eprint = {2302.13971},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2302.13971},
  url = {http://arxiv.org/abs/2302.13971},
  urldate = {2023-10-09},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\AXUZ3EUN\\Touvron et al. - 2023 - LLaMA Open and Efficient Foundation Language Mode.pdf;C\:\\Users\\oskar\\Zotero\\storage\\IKGGGZUG\\2302.html}
}

@misc{touvronLlamaOpenFoundation2023a,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  year = {2023},
  month = jul,
  number = {arXiv:2307.09288},
  eprint = {2307.09288},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2307.09288},
  url = {http://arxiv.org/abs/2307.09288},
  urldate = {2023-12-07},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\PQJCXPA5\\Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf;C\:\\Users\\oskar\\Zotero\\storage\\5BRHXUNL\\2307.html}
}

@misc{unluChatmapLargeLanguage2023,
  title = {Chatmap : {{Large Language Model Interaction}} with {{Cartographic Data}}},
  shorttitle = {Chatmap},
  author = {Unlu, Eren},
  year = {2023},
  month = sep,
  number = {arXiv:2310.01429},
  eprint = {2310.01429},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2310.01429},
  url = {http://arxiv.org/abs/2310.01429},
  urldate = {2023-10-06},
  abstract = {The swift advancement and widespread availability of foundational Large Language Models (LLMs), complemented by robust fine-tuning methodologies, have catalyzed their adaptation for innovative and industrious applications. Enabling LLMs to recognize and interpret geospatial data, while offering a linguistic access to vast cartographic datasets, is of significant importance. OpenStreetMap (OSM) is the most ambitious open-source global initiative offering detailed urban and rural geographic data, curated by a community of over 10 million contributors, which constitutes a great potential for LLM applications. In this study, we demonstrate the proof of concept and details of the process of fine-tuning a relatively small scale (1B parameters) LLM with a relatively small artificial dataset curated by a more capable teacher model, in order to provide a linguistic interface to the OSM data of an arbitrary urban region. Through this interface, users can inquire about a location's attributes, covering a wide spectrum of concepts, such as its touristic appeal or the potential profitability of various businesses in that vicinity. The study aims to provide an initial guideline for such generative artificial intelligence (AI) adaptations and demonstrate early signs of useful emerging abilities in this context even in minimal computational settings. The embeddings of artificially curated prompts including OSM data are also investigated in detail, which might be instrumental for potential geospatially aware urban Retrieval Augmented Generation (RAG) applications.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\BM96N7DH\\Unlu - 2023 - Chatmap  Large Language Model Interaction with Ca.pdf;C\:\\Users\\oskar\\Zotero\\storage\\ZLF9DTRG\\2310.html}
}

@misc{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2017},
  month = jun,
  journal = {arXiv.org},
  url = {https://arxiv.org/abs/1706.03762v7},
  urldate = {2023-10-10},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\KG8K58TW\Vaswani et al. - 2017 - Attention Is All You Need.pdf}
}

@misc{VicunaOpenSourceChatbot,
  title = {Vicuna: {{An Open-Source Chatbot Impressing GPT-4}} with 90\%* {{ChatGPT Quality}} | {{LMSYS Org}}},
  shorttitle = {Vicuna},
  url = {https://lmsys.org/blog/2023-03-30-vicuna},
  urldate = {2023-12-07},
  abstract = {{$<$}p{$>$}We introduce Vicuna-13B, an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Preliminary evaluation ...},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\7KGZJN5B\2023-03-30-vicuna.html}
}

@misc{wangSelfInstructAligningLanguage2023,
  title = {Self-{{Instruct}}: {{Aligning Language Models}} with {{Self-Generated Instructions}}},
  shorttitle = {Self-{{Instruct}}},
  author = {Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},
  year = {2023},
  month = may,
  number = {arXiv:2212.10560},
  eprint = {2212.10560},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2212.10560},
  url = {http://arxiv.org/abs/2212.10560},
  urldate = {2023-10-09},
  abstract = {Large "instruction-tuned" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33\% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5\% absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning. Our code and data are available at https://github.com/yizhongw/self-instruct.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\QCTINMPS\\Wang et al. - 2023 - Self-Instruct Aligning Language Models with Self-.pdf;C\:\\Users\\oskar\\Zotero\\storage\\MEYXTC8V\\2212.html}
}

@misc{weiChainofThoughtPromptingElicits2023,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  year = {2023},
  month = jan,
  number = {arXiv:2201.11903},
  eprint = {2201.11903},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2201.11903},
  url = {http://arxiv.org/abs/2201.11903},
  urldate = {2023-12-11},
  abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\LRRPI8LI\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf;C\:\\Users\\oskar\\Zotero\\storage\\FGEAGYAP\\2201.html}
}

@article{wengLLMPoweredAutonomous2023,
  title = {{{LLM Powered Autonomous Agents}}},
  author = {Weng, Lilian},
  year = {2023},
  month = jun,
  journal = {lilianweng.github.io},
  url = {https://lilianweng.github.io/posts/2023-06-23-agent/},
  urldate = {2023-12-10},
  abstract = {Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver. Agent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent's brain, complemented by several key components:},
  chapter = {posts},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\BKMD7SPN\2023-06-23-agent.html}
}

@misc{WhatVectorDatabase,
  title = {What Is an Vector Database? | {{IBM}}},
  shorttitle = {What Is an Vector Database?},
  url = {https://www.ibm.com/topics/vector-database},
  urldate = {2023-12-11},
  abstract = {A vector database is designed to store, manage and index massive quantities of high-dimensional vector data efficiently.},
  langid = {american}
}

@misc{whitePromptPatternCatalog2023,
  title = {A {{Prompt Pattern Catalog}} to {{Enhance Prompt Engineering}} with {{ChatGPT}}},
  author = {White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and {Spencer-Smith}, Jesse and Schmidt, Douglas C.},
  year = {2023},
  month = feb,
  number = {arXiv:2302.11382},
  eprint = {2302.11382},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2302.11382},
  url = {http://arxiv.org/abs/2302.11382},
  urldate = {2023-10-06},
  abstract = {Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM. This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs. Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs. This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks. First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains. Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations. Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\M7SC9URA\\White et al. - 2023 - A Prompt Pattern Catalog to Enhance Prompt Enginee.pdf;C\:\\Users\\oskar\\Zotero\\storage\\JHQNKRW4\\2302.html}
}

@misc{wuAutoGenEnablingNextGen2023,
  title = {{{AutoGen}}: {{Enabling Next-Gen LLM Applications}} via {{Multi-Agent Conversation}}},
  shorttitle = {{{AutoGen}}},
  author = {Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and Awadallah, Ahmed Hassan and White, Ryen W. and Burger, Doug and Wang, Chi},
  year = {2023},
  month = oct,
  number = {arXiv:2308.08155},
  eprint = {2308.08155},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2308.08155},
  url = {http://arxiv.org/abs/2308.08155},
  urldate = {2023-12-06},
  abstract = {AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\G62PQ5SB\\Wu et al. - 2023 - AutoGen Enabling Next-Gen LLM Applications via Mu.pdf;C\:\\Users\\oskar\\Zotero\\storage\\XCS4SCF5\\2308.html}
}

@article{wurstleViabilityTestingGame2022,
  title = {Viability Testing of Game Engine Usage for Visualization of {{3D}} Geospatial Data with {{OCG}} Standards : 17th {{3D GeoInfo Conference}}, 19-21 {{October}} 2022, {{Sydney}}, {{Australia}}},
  shorttitle = {Viability Testing of Game Engine Usage for Visualization of {{3D}} Geospatial Data with {{OCG}} Standards},
  author = {W{\"u}rstle, Patrick and Padsala, Rushikesh and Santhanavanich, Thunyathep and Coors, Volker},
  year = {2022},
  journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume = {X-4/W2-2022},
  pages = {281--288},
  publisher = {{Leibniz University}},
  url = {https://opus.bsz-bw.de/hft/frontdoor/index/index/docId/387},
  urldate = {2023-10-23},
  abstract = {Urban digital twins have become an essential factor for cities and communities to visualize, simulate and analyze data. The conventional geospatial standards work great with online platforms such as CesiumJS or ArcGIS API for JavaScript. However, their usage in different platforms such as game engines has not been well established yet. Game engines provide an interesting application case because they offer a different approach to visualizing large city models and provide a high graphical fidelity. This paper aims to answer how the existing standards, such as the API standards GeoVolumes and SensorThings, as well as the 3D model standards 3D Tiles and Esri Indexed 3D Scene Layer (I3S), can interact with game engines. For this purpose, three use-cases were selected and have been used to build applications. These focus on using sensor data in AR and different city development scenarios in a digital environment. This study shows that different geospatial standard formats such as 3D Tiles, I3S, and GL Transmission Format (glTF) can be used in game engines, either directly or over a GeoVolumes Server. Their implementation makes it possible to use the advantages of game engines with real-world datasets.},
  copyright = {https://creativecommons.org/licenses/by/4.0/deed.de},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\PA29S2G5\Würstle et al. - 2022 - Viability testing of game engine usage for visuali.pdf}
}

@misc{xueParameterEfficientTuningHelps2023,
  title = {Parameter-{{Efficient Tuning Helps Language Model Alignment}}},
  author = {Xue, Tianci and Wang, Ziqi and Ji, Heng},
  year = {2023},
  month = oct,
  number = {arXiv:2310.00819},
  eprint = {2310.00819},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2310.00819},
  url = {http://arxiv.org/abs/2310.00819},
  urldate = {2023-10-09},
  abstract = {Aligning large language models (LLMs) with human preferences is essential for safe and useful LLMs. Previous works mainly adopt reinforcement learning (RLHF) and direct preference optimization (DPO) with human feedback for alignment. Nevertheless, they have certain drawbacks. One such limitation is that they can only align models with one preference at the training time (e.g., they cannot learn to generate concise responses when the preference data prefers detailed responses), or have certain constraints for the data format (e.g., DPO only supports pairwise preference data). To this end, prior works incorporate controllable generations for alignment to make language models learn multiple preferences and provide outputs with different preferences during inference if asked. Controllable generation also offers more flexibility with regard to data format (e.g., it supports pointwise preference data). Specifically, it uses different control tokens for different preferences during training and inference, making LLMs behave differently when required. Current controllable generation methods either use a special token or hand-crafted prompts as control tokens, and optimize them together with LLMs. As control tokens are typically much lighter than LLMs, this optimization strategy may not effectively optimize control tokens. To this end, we first use parameter-efficient tuning (e.g., prompting tuning and low-rank adaptation) to optimize control tokens and then fine-tune models for controllable generations, similar to prior works. Our approach, alignMEnt with parameter-Efficient Tuning (MEET), improves the quality of control tokens, thus improving controllable generation quality consistently by an apparent margin on two well-recognized datasets compared with prior works.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\Y25RAKZ7\\Xue et al. - 2023 - Parameter-Efficient Tuning Helps Language Model Al.pdf;C\:\\Users\\oskar\\Zotero\\storage\\QECUWTES\\2310.html}
}

@misc{xuRetrievalMeetsLong2023,
  title = {Retrieval Meets {{Long Context Large Language Models}}},
  author = {Xu, Peng and Ping, Wei and Wu, Xianchao and McAfee, Lawrence and Zhu, Chen and Liu, Zihan and Subramanian, Sandeep and Bakhturina, Evelina and Shoeybi, Mohammad and Catanzaro, Bryan},
  year = {2023},
  month = oct,
  number = {arXiv:2310.03025},
  eprint = {2310.03025},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2310.03025},
  url = {http://arxiv.org/abs/2310.03025},
  urldate = {2023-10-05},
  abstract = {Extending the context window of large language models (LLMs) is getting popular recently, while the solution of augmenting LLMs with retrieval has existed for years. The natural questions are: i) Retrieval-augmentation versus long context window, which one is better for downstream tasks? ii) Can both methods be combined to get the best of both worlds? In this work, we answer these questions by studying both solutions using two state-of-the-art pretrained LLMs, i.e., a proprietary 43B GPT and LLaMA2-70B. Perhaps surprisingly, we find that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation. More importantly, we demonstrate that retrieval can significantly improve the performance of LLMs regardless of their extended context window sizes. Our best model, retrieval-augmented LLaMA2-70B with 32K context window, outperforms GPT-3.5-turbo-16k and Davinci003 in terms of average score on seven long context tasks including question answering and query-based summarization. It also outperforms its non-retrieval LLaMA2-70B-32k baseline by a margin, while being much faster at generation. Our study provides general insights on the choice of retrieval-augmentation versus long context extension of LLM for practitioners.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\JRUJKG3V\\Xu et al. - 2023 - Retrieval meets Long Context Large Language Models.pdf;C\:\\Users\\oskar\\Zotero\\storage\\D6E8ZDVE\\2310.html}
}

@misc{yaoReActSynergizingReasoning2023,
  title = {{{ReAct}}: {{Synergizing Reasoning}} and {{Acting}} in {{Language Models}}},
  shorttitle = {{{ReAct}}},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  year = {2023},
  month = mar,
  number = {arXiv:2210.03629},
  eprint = {2210.03629},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2210.03629},
  urldate = {2023-10-05},
  abstract = {While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\QQ336R5B\\Yao et al. - 2023 - ReAct Synergizing Reasoning and Acting in Languag.pdf;C\:\\Users\\oskar\\Zotero\\storage\\42JMXW48\\2210.html}
}

@misc{yaoTreeThoughtsDeliberate2023,
  title = {Tree of {{Thoughts}}: {{Deliberate Problem Solving}} with {{Large Language Models}}},
  shorttitle = {Tree of {{Thoughts}}},
  author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
  year = {2023},
  month = dec,
  number = {arXiv:2305.10601},
  eprint = {2305.10601},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.10601},
  url = {http://arxiv.org/abs/2305.10601},
  urldate = {2023-12-11},
  abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\IRTZJEVP\\Yao et al. - 2023 - Tree of Thoughts Deliberate Problem Solving with .pdf;C\:\\Users\\oskar\\Zotero\\storage\\GZ8PQJKR\\2305.html}
}

@article{yiuTransmissionTruthImitation2023,
  title = {Transmission {{Versus Truth}}, {{Imitation Versus Innovation}}: {{What Children Can Do That Large Language}} and {{Language-and-Vision Models Cannot}} ({{Yet}})},
  shorttitle = {Transmission {{Versus Truth}}, {{Imitation Versus Innovation}}},
  author = {Yiu, Eunice and Kosoy, Eliza and Gopnik, Alison},
  year = {2023},
  month = oct,
  journal = {Perspectives on Psychological Science},
  pages = {17456916231201401},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/17456916231201401},
  url = {https://doi.org/10.1177/17456916231201401},
  urldate = {2023-10-30},
  abstract = {Much discussion about large language models and language-and-vision models has focused on whether these models are intelligent agents. We present an alternative perspective. First, we argue that these artificial intelligence (AI) models are cultural technologies that enhance cultural transmission and are efficient and powerful imitation engines. Second, we explore what AI models can tell us about imitation and innovation by testing whether they can be used to discover new tools and novel causal structures and contrasting their responses with those of human children. Our work serves as a first step in determining which particular representations and competences, as well as which kinds of knowledge or skills, can be derived from particular learning techniques and data. In particular, we explore which kinds of cognitive capacities can be enabled by statistical analysis of large-scale linguistic data. Critically, our findings suggest that machines may need more than large-scale language and image data to allow the kinds of innovation that a small child can produce.},
  langid = {english},
  file = {C:\Users\oskar\Zotero\storage\E64YEMHK\Yiu et al. - 2023 - Transmission Versus Truth, Imitation Versus Innova.pdf}
}

@misc{yoranMakingRetrievalAugmentedLanguage2023,
  title = {Making {{Retrieval-Augmented Language Models Robust}} to {{Irrelevant Context}}},
  author = {Yoran, Ori and Wolfson, Tomer and Ram, Ori and Berant, Jonathan},
  year = {2023},
  month = oct,
  number = {arXiv:2310.01558},
  eprint = {2310.01558},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2310.01558},
  url = {http://arxiv.org/abs/2310.01558},
  urldate = {2023-10-06},
  abstract = {Retrieval-augmented language models (RALMs) hold promise to produce language understanding systems that are are factual, efficient, and up-to-date. An important desideratum of RALMs, is that retrieved information helps model performance when it is relevant, and does not harm performance when it is not. This is particularly important in multi-hop reasoning scenarios, where misuse of irrelevant evidence can lead to cascading errors. However, recent work has shown that retrieval augmentation can sometimes have a negative effect on performance. In this work, we present a thorough analysis on five open-domain question answering benchmarks, characterizing cases when retrieval reduces accuracy. We then propose two methods to mitigate this issue. First, a simple baseline that filters out retrieved passages that do not entail question-answer pairs according to a natural language inference (NLI) model. This is effective in preventing performance reduction, but at a cost of also discarding relevant passages. Thus, we propose a method for automatically generating data to fine-tune the language model to properly leverage retrieved passages, using a mix of relevant and irrelevant contexts at training time. We empirically show that even 1,000 examples suffice to train the model to be robust to irrelevant contexts while maintaining high performance on examples with relevant ones.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\B5WNQJPH\\Yoran et al. - 2023 - Making Retrieval-Augmented Language Models Robust .pdf;C\:\\Users\\oskar\\Zotero\\storage\\H7PN98VX\\2310.html}
}

@misc{zellersHellaSwagCanMachine2019,
  title = {{{HellaSwag}}: {{Can}} a {{Machine Really Finish Your Sentence}}?},
  shorttitle = {{{HellaSwag}}},
  author = {Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  year = {2019},
  month = may,
  number = {arXiv:1905.07830},
  eprint = {1905.07830},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1905.07830},
  url = {http://arxiv.org/abs/1905.07830},
  urldate = {2023-12-09},
  abstract = {Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as "A woman sits at a piano," a machine must select the most likely followup: "She sets her fingers on the keys." With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans ({$>$}95\% accuracy), state-of-the-art models struggle ({$<$}48\%). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical 'Goldilocks' zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\UPR2CQAR\\Zellers et al. - 2019 - HellaSwag Can a Machine Really Finish Your Senten.pdf;C\:\\Users\\oskar\\Zotero\\storage\\P3CK28LB\\1905.html}
}

@misc{zhangGeoGPTUnderstandingProcessing2023,
  title = {{{GeoGPT}}: {{Understanding}} and {{Processing Geospatial Tasks}} through {{An Autonomous GPT}}},
  shorttitle = {{{GeoGPT}}},
  author = {Zhang, Yifan and Wei, Cheng and Wu, Shangyou and He, Zhengting and Yu, Wenhao},
  year = {2023},
  month = jul,
  number = {arXiv:2307.07930},
  eprint = {2307.07930},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2307.07930},
  url = {http://arxiv.org/abs/2307.07930},
  urldate = {2023-10-04},
  abstract = {Decision-makers in GIS need to combine a series of spatial algorithms and operations to solve geospatial tasks. For example, in the task of facility siting, the Buffer tool is usually first used to locate areas close or away from some specific entities; then, the Intersect or Erase tool is used to select candidate areas satisfied multiple requirements. Though professionals can easily understand and solve these geospatial tasks by sequentially utilizing relevant tools, it is difficult for non-professionals to handle these problems. Recently, Generative Pre-trained Transformer (e.g., ChatGPT) presents strong performance in semantic understanding and reasoning. Especially, AutoGPT can further extend the capabilities of large language models (LLMs) by automatically reasoning and calling externally defined tools. Inspired by these studies, we attempt to lower the threshold of non-professional users to solve geospatial tasks by integrating the semantic understanding ability inherent in LLMs with mature tools within the GIS community. Specifically, we develop a new framework called GeoGPT that can conduct geospatial data collection, processing, and analysis in an autonomous manner with the instruction of only natural language. In other words, GeoGPT is used to understand the demands of non-professional users merely based on input natural language descriptions, and then think, plan, and execute defined GIS tools to output final effective results. Several cases including geospatial data crawling, spatial query, facility siting, and mapping validate the effectiveness of our framework. Though limited cases are presented in this paper, GeoGPT can be further extended to various tasks by equipping with more GIS tools, and we think the paradigm of "foundational plus professional" implied in GeoGPT provides an effective way to develop next-generation GIS in this era of large foundation models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\F6ZE4DD9\\Zhang et al. - 2023 - GeoGPT Understanding and Processing Geospatial Ta.pdf;C\:\\Users\\oskar\\Zotero\\storage\\GYMENGQZ\\2307.html}
}

@article{zhengDynamicPromptbasedVirtual2023b,
  title = {Dynamic Prompt-Based Virtual Assistant Framework for {{BIM}} Information Search},
  author = {Zheng, Junwen and Fischer, Martin},
  year = {2023},
  month = nov,
  journal = {Automation in Construction},
  volume = {155},
  pages = {105067},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2023.105067},
  url = {https://www.sciencedirect.com/science/article/pii/S0926580523003278},
  urldate = {2023-10-04},
  abstract = {Efficient information search from building information models (BIMs) requires deep BIM knowledge or extensive engineering efforts for building natural language (NL)-based interfaces. To address this challenge, this paper introduces a dynamic prompt-based virtual assistant framework dubbed ``BIMS-GPT'' that integrates generative pre-trained transformer (GPT) technologies, supporting NL-based BIM search. To understand users' NL queries, extract relevant information from BIM databases, and deliver NL responses along with 3D visualizations, a dynamic prompt-based process was developed. In a case study, BIMS-GPT's functionality is demonstrated through a virtual assistant prototype for a hospital building. When evaluated with a BIM query dataset, the approach achieves accuracy rates of 99.5\% for classifying NL queries with incorporating 2\% of the data in prompts. This paper contributes to the advancement of effective and versatile virtual assistants for BIMs in the construction industry as it significantly enhances BIM accessibility while reducing the engineering and training data prerequisites for processing NL queries.},
  keywords = {Artificial intelligence,BIMS-GPT,Building information modeling,Generative pre-trained transformer,Information retrieval,Information search,Large language model,Natural language processing,Prompt engineering,Virtual assistant},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\75F3SL4G\\Zheng and Fischer - 2023 - Dynamic prompt-based virtual assistant framework f.pdf;C\:\\Users\\oskar\\Zotero\\storage\\KVF8FKTL\\S0926580523003278.html;C\:\\Users\\oskar\\Zotero\\storage\\NE7D6R85\\display.html}
}

@misc{zhouLanguageAgentTree2023,
  title = {Language {{Agent Tree Search Unifies Reasoning Acting}} and {{Planning}} in {{Language Models}}},
  author = {Zhou, Andy and Yan, Kai and {Shlapentokh-Rothman}, Michal and Wang, Haohan and Wang, Yu-Xiong},
  year = {2023},
  month = oct,
  number = {arXiv:2310.04406},
  eprint = {2310.04406},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2310.04406},
  urldate = {2023-10-30},
  abstract = {While large language models (LLMs) have demonstrated impressive performance on a range of decision-making tasks, they rely on simple acting processes and fall short of broad deployment as autonomous agents. We introduce LATS (Language Agent Tree Search), a general framework that synergizes the capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration from Monte Carlo tree search in model-based reinforcement learning, LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. What is crucial in this method is the use of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that moves beyond the limitations of existing techniques. Our experimental evaluation across diverse domains, such as programming, HotPotQA, and WebShop, illustrates the applicability of LATS for both reasoning and acting. In particular, LATS achieves 94.4{\textbackslash}\% for programming on HumanEval with GPT-4 and an average score of 75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness and generality of our method.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\WFHLX8XB\\Zhou et al. - 2023 - Language Agent Tree Search Unifies Reasoning Actin.pdf;C\:\\Users\\oskar\\Zotero\\storage\\D6MBARZ8\\2310.html}
}

@article{zuoTopicModelingShort2023,
  title = {Topic {{Modeling}} of {{Short Texts}}: {{A Pseudo-Document View With Word Embedding Enhancement}}},
  shorttitle = {Topic {{Modeling}} of {{Short Texts}}},
  author = {Zuo, Yuan and Li, Congrui and Lin, Hao and Wu, Junjie},
  year = {2023},
  month = jan,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {35},
  number = {1},
  pages = {972--985},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2021.3073195},
  url = {https://ieeexplore.ieee.org/document/9404875},
  urldate = {2023-10-09},
  abstract = {Recent years have witnessed the unprecedented growth of online social media, resulting in short texts being the prevalent format of information on the Internet. Given the sparsity of data, however, short-text topic modeling remains a critical yet much-watched challenge in both academia and industry. Research has been devoted to building different types of probabilistic topic models for short texts, among which self-aggregation methods emerged recently to provide informative cross-text word co-occurrences. However, models along this line are still in their infancy and typically yield overfit results and exhibit high computational costs. In this paper, we propose a novel model called Pseudo-document-based Topic Model (PTM), which introduces the concept of pseudo-document to implicitly aggregate short texts against data sparsity. By modeling the topic distributions of latent pseudo-documents rather than short texts, PTM yields excellent performance in accuracy and efficiency. A word embedding-enhanced PTM (WE-PTM) is also proposed to leverage pre-trained word embeddings, which is essential to further alleviating data sparsity. Extensive experiments with self-aggregation or word embedding-based baselines on four real-world datasets including two online media short texts, demonstrate the high-quality topics learned by our models. Robustness to limited training samples and the explainable semantics of topics are also investigated.},
  file = {C\:\\Users\\oskar\\Zotero\\storage\\PXSBHXC9\\Zuo et al. - 2023 - Topic Modeling of Short Texts A Pseudo-Document V.pdf;C\:\\Users\\oskar\\Zotero\\storage\\L8UZJ8S5\\9404875.html}
}
